{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:04:07.223678Z",
     "start_time": "2020-05-07T01:04:07.203114Z"
    }
   },
   "outputs": [],
   "source": [
    "# If you run this notebook on Google Colaboratory, uncomment the below to install automl_alex.\n",
    "#!pip install -q -U automl_alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:05:50.878720Z",
     "start_time": "2020-05-07T01:05:50.874642Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AutoML-Alex version: 1.3.5\n"
     ]
    }
   ],
   "source": [
    "import automl_alex\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import time\n",
    "from automl_alex import DataPrepare\n",
    "from automl_alex import AutoML, AutoMLClassifier, AutoMLRegressor\n",
    "print('AutoML-Alex version:', automl_alex.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:05:52.553896Z",
     "start_time": "2020-05-07T01:05:52.549132Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:05:55.127924Z",
     "start_time": "2020-05-07T01:05:55.037616Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  age         workclass    fnlwgt  education  education-num  \\\n",
       "0   2         State-gov   77516.0  Bachelors           13.0   \n",
       "1   3  Self-emp-not-inc   83311.0  Bachelors           13.0   \n",
       "2   2           Private  215646.0    HS-grad            9.0   \n",
       "3   3           Private  234721.0       11th            7.0   \n",
       "4   1           Private  338409.0  Bachelors           13.0   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "  capitalgain capitalloss hoursperweek native-country  \n",
       "0           1           0            2  United-States  \n",
       "1           0           0            0  United-States  \n",
       "2           0           0            2  United-States  \n",
       "3           0           0            2  United-States  \n",
       "4           0           0            2           Cuba  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capitalgain</th>\n      <th>capitalloss</th>\n      <th>hoursperweek</th>\n      <th>native-country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>State-gov</td>\n      <td>77516.0</td>\n      <td>Bachelors</td>\n      <td>13.0</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311.0</td>\n      <td>Bachelors</td>\n      <td>13.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Private</td>\n      <td>215646.0</td>\n      <td>HS-grad</td>\n      <td>9.0</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Private</td>\n      <td>234721.0</td>\n      <td>11th</td>\n      <td>7.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Private</td>\n      <td>338409.0</td>\n      <td>Bachelors</td>\n      <td>13.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Cuba</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "# https://www.openml.org/d/179\n",
    "dataset = fetch_openml(data_id=179, as_frame=True)\n",
    "dataset.target = dataset.target.astype('category').cat.codes\n",
    "dataset.data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:05:56.756465Z",
     "start_time": "2020-05-07T01:05:56.734220Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((36631, 14), (12211, 14))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, \n",
    "                                                    dataset.target,\n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=RANDOM_SEED,)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "source": [
    "## AutoML"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "01:23:34 | > Start Fit Base Model\n",
      "01:24:15 | > DATA PREPROC\n",
      "01:24:15 | Source data shape: (36631, 14)\n",
      "01:24:15 | ##################################################\n",
      "01:24:15 | ! START preprocessing Data\n",
      "01:24:15 | - Auto detect cat features: 12\n",
      "01:24:15 | > Binary Features\n",
      "01:24:15 | > Clean Categorical Features\n",
      "01:24:16 | > Transform Categorical Features.\n",
      "01:24:16 |  - Encoder: OneHotEncoder ADD features: 135\n",
      "01:24:16 |  - Encoder: CountEncoder ADD features: 12\n",
      "01:24:16 |   No nans features\n",
      "01:24:16 | > CleanOutliers\n",
      "01:24:16 | Num of outlier detected: 527 in Feature fnlwgt\n",
      "01:24:16 | Proportion of outlier detected: 1.4 %\n",
      "01:24:16 | Num of outlier detected: 231 in Feature education-num\n",
      "01:24:16 | Proportion of outlier detected: 0.6 %\n",
      "01:24:17 | > Generate interaction Num Features\n",
      "01:24:17 |  ADD features: 5\n",
      "01:24:17 | > Normalization Features\n",
      "01:24:17 | ##################################################\n",
      "01:24:17 | Final data shape: (36631, 168)\n",
      "01:24:17 | Total ADD columns: 154\n",
      "01:24:17 | ##################################################\n",
      "01:24:17 | ##################################################\n",
      "01:24:17 | > Start Fit Models 3\n",
      "01:24:17 | ##################################################\n",
      "01:24:37 | > DATA PREPROC\n",
      "01:24:37 | Source data shape: (36631, 14)\n",
      "01:24:37 | ##################################################\n",
      "01:24:37 | ! START preprocessing Data\n",
      "01:24:37 | - Auto detect cat features: 12\n",
      "01:24:37 | > Binary Features\n",
      "01:24:37 | > Clean Categorical Features\n",
      "01:24:37 | > Transform Categorical Features.\n",
      "01:24:37 |  - Encoder: HelmertEncoder ADD features: 123\n",
      "01:24:38 |  - Encoder: CountEncoder ADD features: 12\n",
      "01:24:38 |  - Encoder: HashingEncoder ADD features: 12\n",
      "01:24:38 |   No nans features\n",
      "01:24:38 | > CleanOutliers\n",
      "01:24:38 | Num of outlier detected: 527 in Feature fnlwgt\n",
      "01:24:38 | Proportion of outlier detected: 1.4 %\n",
      "01:24:38 | Num of outlier detected: 231 in Feature education-num\n",
      "01:24:38 | Proportion of outlier detected: 0.6 %\n",
      "01:24:38 | > Generate interaction Num Features\n",
      "01:24:38 |  ADD features: 5\n",
      "01:24:38 | ##################################################\n",
      "01:24:38 | Final data shape: (36631, 168)\n",
      "01:24:38 | Total ADD columns: 154\n",
      "01:24:38 | ##################################################\n",
      "01:24:38 | ##################################################\n",
      "01:24:38 | > Start Fit Models 4\n",
      "01:24:53 | ##################################################\n",
      "01:24:53 | > Start Fit Models 5\n",
      "01:24:53 | ##################################################\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Save model\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<automl_alex.automl_alex.AutoMLClassifier at 0x7f6da59acb80>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "model = AutoMLClassifier(random_state=RANDOM_SEED,)\n",
    "model.fit(X_train, y_train, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Load CrossValidation\n",
      "Load model\n"
     ]
    }
   ],
   "source": [
    "predicts = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test AUC:  0.9137\n"
     ]
    }
   ],
   "source": [
    "print('Test AUC: ', round(sklearn.metrics.roc_auc_score(y_test, predicts),4))"
   ]
  },
  {
   "source": [
    "## Save & Load"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Save model\n"
     ]
    }
   ],
   "source": [
    "model.save('AutoML_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "01:40:22 | Load DataPrepare\n",
      "01:40:22 | Load DataPrepare\n",
      "01:40:22 | Load Model\n",
      "Finished loading model, total used 300 iterations\n",
      "01:40:22 | Load Model\n",
      "Finished loading model, total used 300 iterations\n",
      "01:40:22 | Load Model\n",
      "Finished loading model, total used 300 iterations\n",
      "01:40:22 | Load Model\n",
      "Finished loading model, total used 300 iterations\n",
      "01:40:22 | Load Model\n",
      "Finished loading model, total used 300 iterations\n",
      "01:40:23 | Load Model\n",
      "Finished loading model, total used 300 iterations\n",
      "01:40:23 | Load Model\n",
      "Finished loading model, total used 300 iterations\n",
      "Load CrossValidation\n",
      "Load model\n",
      "01:40:23 | Load AutoML\n"
     ]
    }
   ],
   "source": [
    "model_new = AutoMLClassifier(random_state=RANDOM_SEED,)\n",
    "model_new = model_new.load('AutoML_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Load CrossValidation\n",
      "Load model\n",
      "Test AUC:  0.9131\n"
     ]
    }
   ],
   "source": [
    "predicts = model_new.predict(X_test)\n",
    "print('Test AUC: ', round(sklearn.metrics.roc_auc_score(y_test, predicts),4))"
   ]
  },
  {
   "source": [
    "# Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((430, 19), (76, 19))"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# https://www.openml.org/d/543\n",
    "dataset = fetch_openml(data_id=543, as_frame=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(dataset.data), \n",
    "                                                    pd.DataFrame(dataset.target), \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=RANDOM_SEED,)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   TOWN  TOWN_ID   TRACT      LON      LAT  MEDV  CMEDV  \\\n",
       "104             Medford     24.0  3395.0 -71.0690  42.2480  20.1   20.1   \n",
       "203              Weston     37.0  3671.0 -71.1990  42.2320  48.5   48.5   \n",
       "381  Boston_East_Boston     79.0   407.0 -71.0410  42.2290  10.9   10.9   \n",
       "489             Chelsea     89.0  1602.0 -71.0228  42.2335   7.0    7.0   \n",
       "69           Wilmington     16.0  3313.0 -71.1110  42.3270  20.9   20.9   \n",
       "\n",
       "         CRIM    ZN  INDUS CHAS     NOX     RM   AGE     DIS RAD    TAX  \\\n",
       "104   0.13960   0.0   8.56    0  0.5200  6.167  90.0  2.4210   5  384.0   \n",
       "203   0.03510  95.0   2.68    0  0.4161  7.853  33.2  5.1180   4  224.0   \n",
       "381  15.87440   0.0  18.10    0  0.6710  6.545  99.1  1.5192  24  666.0   \n",
       "489   0.18337   0.0  27.74    0  0.6090  5.414  98.3  1.7554   4  711.0   \n",
       "69    0.12816  12.5   6.07    0  0.4090  5.885  33.0  6.4980   4  345.0   \n",
       "\n",
       "     PTRATIO       B  \n",
       "104     20.9  392.69  \n",
       "203     14.7  392.78  \n",
       "381     20.2  396.90  \n",
       "489     20.1  344.05  \n",
       "69      18.9  396.90  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TOWN</th>\n      <th>TOWN_ID</th>\n      <th>TRACT</th>\n      <th>LON</th>\n      <th>LAT</th>\n      <th>MEDV</th>\n      <th>CMEDV</th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>104</th>\n      <td>Medford</td>\n      <td>24.0</td>\n      <td>3395.0</td>\n      <td>-71.0690</td>\n      <td>42.2480</td>\n      <td>20.1</td>\n      <td>20.1</td>\n      <td>0.13960</td>\n      <td>0.0</td>\n      <td>8.56</td>\n      <td>0</td>\n      <td>0.5200</td>\n      <td>6.167</td>\n      <td>90.0</td>\n      <td>2.4210</td>\n      <td>5</td>\n      <td>384.0</td>\n      <td>20.9</td>\n      <td>392.69</td>\n    </tr>\n    <tr>\n      <th>203</th>\n      <td>Weston</td>\n      <td>37.0</td>\n      <td>3671.0</td>\n      <td>-71.1990</td>\n      <td>42.2320</td>\n      <td>48.5</td>\n      <td>48.5</td>\n      <td>0.03510</td>\n      <td>95.0</td>\n      <td>2.68</td>\n      <td>0</td>\n      <td>0.4161</td>\n      <td>7.853</td>\n      <td>33.2</td>\n      <td>5.1180</td>\n      <td>4</td>\n      <td>224.0</td>\n      <td>14.7</td>\n      <td>392.78</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>Boston_East_Boston</td>\n      <td>79.0</td>\n      <td>407.0</td>\n      <td>-71.0410</td>\n      <td>42.2290</td>\n      <td>10.9</td>\n      <td>10.9</td>\n      <td>15.87440</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0</td>\n      <td>0.6710</td>\n      <td>6.545</td>\n      <td>99.1</td>\n      <td>1.5192</td>\n      <td>24</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>396.90</td>\n    </tr>\n    <tr>\n      <th>489</th>\n      <td>Chelsea</td>\n      <td>89.0</td>\n      <td>1602.0</td>\n      <td>-71.0228</td>\n      <td>42.2335</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>0.18337</td>\n      <td>0.0</td>\n      <td>27.74</td>\n      <td>0</td>\n      <td>0.6090</td>\n      <td>5.414</td>\n      <td>98.3</td>\n      <td>1.7554</td>\n      <td>4</td>\n      <td>711.0</td>\n      <td>20.1</td>\n      <td>344.05</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>Wilmington</td>\n      <td>16.0</td>\n      <td>3313.0</td>\n      <td>-71.1110</td>\n      <td>42.3270</td>\n      <td>20.9</td>\n      <td>20.9</td>\n      <td>0.12816</td>\n      <td>12.5</td>\n      <td>6.07</td>\n      <td>0</td>\n      <td>0.4090</td>\n      <td>5.885</td>\n      <td>33.0</td>\n      <td>6.4980</td>\n      <td>4</td>\n      <td>345.0</td>\n      <td>18.9</td>\n      <td>396.90</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "source": [
    "## AutoML"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "01:40:29 | Source data shape: (430, 19)\n",
      "01:40:29 | ##################################################\n",
      "01:40:29 | ! START preprocessing Data\n",
      "01:40:29 | > Binary Features\n",
      "01:40:29 | > Clean Categorical Features\n",
      "01:40:29 |   No nans features\n",
      "01:40:29 | > CleanOutliers\n",
      "01:40:29 | Num of outlier detected: 1 in Feature DIS\n",
      "01:40:29 | Proportion of outlier detected: 0.2 %\n",
      "01:40:30 | Num of outlier detected: 49 in Feature ZN\n",
      "01:40:30 | Proportion of outlier detected: 11.4 %\n",
      "01:40:30 | Num of outlier detected: 15 in Feature RM\n",
      "01:40:30 | Proportion of outlier detected: 3.5 %\n",
      "01:40:30 | Num of outlier detected: 27 in Feature CMEDV\n",
      "01:40:30 | Proportion of outlier detected: 6.3 %\n",
      "01:40:30 | Num of outlier detected: 47 in Feature CRIM\n",
      "01:40:30 | Proportion of outlier detected: 10.9 %\n",
      "01:40:30 | Num of outlier detected: 26 in Feature MEDV\n",
      "01:40:30 | Proportion of outlier detected: 6.0 %\n",
      "01:40:30 | Num of outlier detected: 60 in Feature B\n",
      "01:40:30 | Proportion of outlier detected: 14.0 %\n",
      "01:40:30 | Num of outlier detected: 18 in Feature LON\n",
      "01:40:30 | Proportion of outlier detected: 4.2 %\n",
      "01:40:30 | > Generate interaction Num Features\n",
      "01:40:30 |  ADD features: 600\n",
      "01:40:30 | > Normalization Features\n",
      "01:40:30 | ##################################################\n",
      "01:40:30 | Final data shape: (430, 635)\n",
      "01:40:30 | Total ADD columns: 616\n",
      "01:40:30 | ##################################################\n",
      "01:40:30 | ##################################################\n",
      "01:40:30 | > Start Fit Models 3\n",
      "01:40:30 | ##################################################\n",
      "01:40:32 | > DATA PREPROC\n",
      "01:40:32 | Source data shape: (430, 19)\n",
      "01:40:32 | ##################################################\n",
      "01:40:32 | ! START preprocessing Data\n",
      "01:40:32 | > Binary Features\n",
      "01:40:32 | > Clean Categorical Features\n",
      "01:40:32 |   No nans features\n",
      "01:40:32 | > CleanOutliers\n",
      "01:40:32 | Num of outlier detected: 1 in Feature DIS\n",
      "01:40:32 | Proportion of outlier detected: 0.2 %\n",
      "01:40:32 | Num of outlier detected: 49 in Feature ZN\n",
      "01:40:32 | Proportion of outlier detected: 11.4 %\n",
      "01:40:32 | Num of outlier detected: 15 in Feature RM\n",
      "01:40:32 | Proportion of outlier detected: 3.5 %\n",
      "01:40:32 | Num of outlier detected: 27 in Feature CMEDV\n",
      "01:40:32 | Proportion of outlier detected: 6.3 %\n",
      "01:40:32 | Num of outlier detected: 47 in Feature CRIM\n",
      "01:40:32 | Proportion of outlier detected: 10.9 %\n",
      "01:40:32 | Num of outlier detected: 26 in Feature MEDV\n",
      "01:40:32 | Proportion of outlier detected: 6.0 %\n",
      "01:40:32 | Num of outlier detected: 60 in Feature B\n",
      "01:40:32 | Proportion of outlier detected: 14.0 %\n",
      "01:40:32 | Num of outlier detected: 18 in Feature LON\n",
      "01:40:32 | Proportion of outlier detected: 4.2 %\n",
      "01:40:32 | > Generate interaction Num Features\n",
      "01:40:32 |  ADD features: 600\n",
      "01:40:33 | ##################################################\n",
      "01:40:33 | Final data shape: (430, 635)\n",
      "01:40:33 | Total ADD columns: 616\n",
      "01:40:33 | ##################################################\n",
      "01:40:33 | ##################################################\n",
      "01:40:33 | > Start Fit Models 4\n",
      "01:41:44 | ##################################################\n",
      "01:41:44 | > Start Fit Models 5\n",
      "01:41:44 | ##################################################\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Save model\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<automl_alex.automl_alex.AutoMLRegressor at 0x7f6da5826190>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model = AutoMLRegressor(random_state=RANDOM_SEED,)\n",
    "model.fit(X_train, y_train, timeout=900, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Load CrossValidation\n",
      "Load model\n",
      "Test MSE:  6.8811\n"
     ]
    }
   ],
   "source": [
    "predicts = model.predict(X_test)\n",
    "print('Test MSE: ', round(sklearn.metrics.mean_squared_error(y_test, predicts),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}