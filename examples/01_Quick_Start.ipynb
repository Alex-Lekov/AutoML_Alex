{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:04:07.223678Z",
     "start_time": "2020-05-07T01:04:07.203114Z"
    }
   },
   "outputs": [],
   "source": [
    "# If you run this notebook on Google Colaboratory, uncomment the below to install automl_alex.\n",
    "#!pip install -q -U automl_alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:05:50.878720Z",
     "start_time": "2020-05-07T01:05:50.874642Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AutoML-Alex version: 0.11.24\n"
     ]
    }
   ],
   "source": [
    "import automl_alex\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import time\n",
    "from automl_alex import AutoML, AutoMLClassifier, AutoMLRegressor\n",
    "print('AutoML-Alex version:', automl_alex.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:05:52.553896Z",
     "start_time": "2020-05-07T01:05:52.549132Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:05:55.127924Z",
     "start_time": "2020-05-07T01:05:55.037616Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  checking_status  duration                  credit_history  \\\n",
       "0              <0       6.0  critical/other existing credit   \n",
       "1        0<=X<200      48.0                   existing paid   \n",
       "2     no checking      12.0  critical/other existing credit   \n",
       "3              <0      42.0                   existing paid   \n",
       "4              <0      24.0              delayed previously   \n",
       "\n",
       "               purpose  credit_amount    savings_status employment  \\\n",
       "0             radio/tv         1169.0  no known savings        >=7   \n",
       "1             radio/tv         5951.0              <100     1<=X<4   \n",
       "2            education         2096.0              <100     4<=X<7   \n",
       "3  furniture/equipment         7882.0              <100     4<=X<7   \n",
       "4              new car         4870.0              <100     1<=X<4   \n",
       "\n",
       "   installment_commitment     personal_status other_parties  residence_since  \\\n",
       "0                     4.0         male single          none              4.0   \n",
       "1                     2.0  female div/dep/mar          none              2.0   \n",
       "2                     2.0         male single          none              3.0   \n",
       "3                     2.0         male single     guarantor              4.0   \n",
       "4                     3.0         male single          none              4.0   \n",
       "\n",
       "  property_magnitude   age other_payment_plans   housing  existing_credits  \\\n",
       "0        real estate  67.0                none       own               2.0   \n",
       "1        real estate  22.0                none       own               1.0   \n",
       "2        real estate  49.0                none       own               1.0   \n",
       "3     life insurance  45.0                none  for free               1.0   \n",
       "4  no known property  53.0                none  for free               2.0   \n",
       "\n",
       "                  job  num_dependents own_telephone foreign_worker  \n",
       "0             skilled             1.0           yes            yes  \n",
       "1             skilled             1.0          none            yes  \n",
       "2  unskilled resident             2.0          none            yes  \n",
       "3             skilled             2.0          none            yes  \n",
       "4             skilled             2.0          none            yes  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>checking_status</th>\n      <th>duration</th>\n      <th>credit_history</th>\n      <th>purpose</th>\n      <th>credit_amount</th>\n      <th>savings_status</th>\n      <th>employment</th>\n      <th>installment_commitment</th>\n      <th>personal_status</th>\n      <th>other_parties</th>\n      <th>residence_since</th>\n      <th>property_magnitude</th>\n      <th>age</th>\n      <th>other_payment_plans</th>\n      <th>housing</th>\n      <th>existing_credits</th>\n      <th>job</th>\n      <th>num_dependents</th>\n      <th>own_telephone</th>\n      <th>foreign_worker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;0</td>\n      <td>6.0</td>\n      <td>critical/other existing credit</td>\n      <td>radio/tv</td>\n      <td>1169.0</td>\n      <td>no known savings</td>\n      <td>&gt;=7</td>\n      <td>4.0</td>\n      <td>male single</td>\n      <td>none</td>\n      <td>4.0</td>\n      <td>real estate</td>\n      <td>67.0</td>\n      <td>none</td>\n      <td>own</td>\n      <td>2.0</td>\n      <td>skilled</td>\n      <td>1.0</td>\n      <td>yes</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0&lt;=X&lt;200</td>\n      <td>48.0</td>\n      <td>existing paid</td>\n      <td>radio/tv</td>\n      <td>5951.0</td>\n      <td>&lt;100</td>\n      <td>1&lt;=X&lt;4</td>\n      <td>2.0</td>\n      <td>female div/dep/mar</td>\n      <td>none</td>\n      <td>2.0</td>\n      <td>real estate</td>\n      <td>22.0</td>\n      <td>none</td>\n      <td>own</td>\n      <td>1.0</td>\n      <td>skilled</td>\n      <td>1.0</td>\n      <td>none</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>no checking</td>\n      <td>12.0</td>\n      <td>critical/other existing credit</td>\n      <td>education</td>\n      <td>2096.0</td>\n      <td>&lt;100</td>\n      <td>4&lt;=X&lt;7</td>\n      <td>2.0</td>\n      <td>male single</td>\n      <td>none</td>\n      <td>3.0</td>\n      <td>real estate</td>\n      <td>49.0</td>\n      <td>none</td>\n      <td>own</td>\n      <td>1.0</td>\n      <td>unskilled resident</td>\n      <td>2.0</td>\n      <td>none</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;0</td>\n      <td>42.0</td>\n      <td>existing paid</td>\n      <td>furniture/equipment</td>\n      <td>7882.0</td>\n      <td>&lt;100</td>\n      <td>4&lt;=X&lt;7</td>\n      <td>2.0</td>\n      <td>male single</td>\n      <td>guarantor</td>\n      <td>4.0</td>\n      <td>life insurance</td>\n      <td>45.0</td>\n      <td>none</td>\n      <td>for free</td>\n      <td>1.0</td>\n      <td>skilled</td>\n      <td>2.0</td>\n      <td>none</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;0</td>\n      <td>24.0</td>\n      <td>delayed previously</td>\n      <td>new car</td>\n      <td>4870.0</td>\n      <td>&lt;100</td>\n      <td>1&lt;=X&lt;4</td>\n      <td>3.0</td>\n      <td>male single</td>\n      <td>none</td>\n      <td>4.0</td>\n      <td>no known property</td>\n      <td>53.0</td>\n      <td>none</td>\n      <td>for free</td>\n      <td>2.0</td>\n      <td>skilled</td>\n      <td>2.0</td>\n      <td>none</td>\n      <td>yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = fetch_openml(name='credit-g', version=1, as_frame=True)\n",
    "dataset.target = dataset.target.astype('category').cat.codes\n",
    "dataset.data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:05:56.756465Z",
     "start_time": "2020-05-07T01:05:56.734220Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((750, 20), (250, 20))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, \n",
    "                                                    dataset.target,\n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=RANDOM_SEED,)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:05:59.848085Z",
     "start_time": "2020-05-07T01:05:59.337884Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Source X_train shape:  (750, 20) | X_test shape:  (250, 20)\n",
      "##################################################\n",
      "Auto detect cat features:  13\n",
      "> Start preprocessing Data\n",
      "> Generate cat encodet features\n",
      " +  55  Features from  OneHotEncoder\n",
      " +  44  Features from  HelmertEncoder\n",
      " +  54  Features from  HashingEncoder\n",
      " +  16  Features from  FrequencyEncoder\n",
      "> Generate Frequency Encode num features\n",
      " +  4  Frequency Encode Num Features \n",
      "> Clean Nans in num features\n",
      "> Generate interaction Num Features\n",
      " +  24  Interaction Features\n",
      "> Normalization Features\n",
      "##################################################\n",
      "> Total Features:  201\n",
      "##################################################\n",
      "New X_train shape:  (750, 201) | X_test shape:  (250, 201)\n"
     ]
    }
   ],
   "source": [
    "#model = AutoML(X_train, y_train, X_test, type_of_estimator='classifier', random_state=RANDOM_SEED)\n",
    "\n",
    "# or Simply\n",
    "model = AutoMLClassifier(X_train, y_train, X_test, random_state=RANDOM_SEED, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T17:01:04.947762Z",
     "start_time": "2020-05-06T16:47:23.396089Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "__________________________________________________\n",
      "Step 1: Model 0\n",
      "__________________________________________________\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.43s/it]\n",
      "--------------------------------------------------\n",
      "Model 1\n",
      "One iteration takes ~ 1.1 sec\n",
      "> Start Auto calibration parameters\n",
      "\u001b[32m[I 2020-11-22 17:40:49,380]\u001b[0m A new study created in memory with name: no-name-bc95aced-4166-4a42-b077-31385c3f2e68\u001b[0m\n",
      "> Start optimization with the parameters:\n",
      "CV_Folds =  10\n",
      "Score_CV_Folds =  3\n",
      "Feature_Selection =  True\n",
      "Opt_lvl =  2\n",
      "Cold_start =  55.0\n",
      "Early_stoping =  100\n",
      "Metric =  roc_auc_score\n",
      "Direction =  maximize\n",
      "##################################################\n",
      "Default model OptScore = 0.6906\n",
      "Optimize: : 184it [14:57,  4.88s/it,  | Model: RandomForest | OptScore: 0.7704 | Best roc_auc_score: 0.8097 +- 0.039278]\n",
      "\n",
      " Predict from Models_1\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.23s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      " > Calc predict policy on Models_1:\n",
      " | posible_repeats:  8  | stack_top:  4  | n_repeats:  2\n",
      " 25%|██▌       | 1/4 [00:35<01:45, 35.00s/it]\n",
      " Mean Score roc_auc_score on 20 Folds: 0.7838 std: 0.038969\n",
      " 50%|█████     | 2/4 [01:14<01:12, 36.36s/it]\n",
      " Mean Score roc_auc_score on 20 Folds: 0.7843 std: 0.039836\n",
      " 75%|███████▌  | 3/4 [02:02<00:39, 39.78s/it]\n",
      " Mean Score roc_auc_score on 20 Folds: 0.7851 std: 0.03985\n",
      "100%|██████████| 4/4 [02:38<00:00, 39.54s/it]\n",
      " Mean Score roc_auc_score on 20 Folds: 0.7835 std: 0.038533\n",
      "\n",
      " Models_1 Mean roc_auc_score Score Train:  0.7833\n",
      "--------------------------------------------------\n",
      "Model 2\n",
      "\n",
      "One iteration takes ~ 1.6 sec\n",
      "> Start Auto calibration parameters\n",
      "> Start optimization with the parameters:\n",
      "CV_Folds =  5\n",
      "Score_CV_Folds =  2\n",
      "Feature_Selection =  True\n",
      "Opt_lvl =  1\n",
      "Cold_start =  63.0\n",
      "Early_stoping =  100\n",
      "Metric =  roc_auc_score\n",
      "Direction =  maximize\n",
      "##################################################\n",
      "Default model OptScore = 0.7672\n",
      "Optimize: : 174it [01:29,  2.28it/s,  | Model: LinearModel | OptScore: 0.7626 | Best roc_auc_score: 0.7689 +- 0.006349]\n",
      " EarlyStopping Exceeded: Best Score: 0.7626 roc_auc_score\n",
      "Optimize: : 174it [01:29,  1.95it/s,  | Model: LinearModel | OptScore: 0.7626 | Best roc_auc_score: 0.7689 +- 0.006349]\n",
      "\n",
      " Predict from Models_2\n",
      " 50%|█████     | 1/2 [00:00<00:00,  1.42it/s]\n",
      " Mean Score roc_auc_score on 5 Folds: 0.7618 std: 0.016025\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.10it/s]\n",
      " Mean Score roc_auc_score on 5 Folds: 0.7617 std: 0.016081\n",
      "\n",
      " Models_2 Mean roc_auc_score Score Train:  0.7604\n",
      "\n",
      " Mean Models roc_auc_score Score Train:  0.791\n",
      "__________________________________________________\n",
      "Step 2: Stacking\n",
      "__________________________________________________\n",
      "\n",
      "New X_train:  (750, 6)  y_train:  (750, 1) | X_test shape:  (250, 6)\n",
      "One iteration takes ~ 0.6 sec\n",
      "> Start optimization with the parameters:\n",
      "CV_Folds =  10\n",
      "Score_CV_Folds =  10\n",
      "Feature_Selection =  True\n",
      "Opt_lvl =  3\n",
      "Cold_start =  25\n",
      "Early_stoping =  100\n",
      "Metric =  roc_auc_score\n",
      "Direction =  maximize\n",
      "##################################################\n",
      "Default model OptScore = 0.7254\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      " 50%|█████     | 1/2 [00:00<00:00,  2.62it/s]\n",
      " Mean Score roc_auc_score on 20 Folds: 0.7924 std: 0.043458\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.64it/s]\n",
      " Mean Score roc_auc_score on 20 Folds: 0.7923 std: 0.043382\n",
      "\n",
      " Stacking model roc_auc_score Score Train:  0.7893\n",
      "\n",
      " Final Model roc_auc_score Score Train:  0.791\n",
      "\n",
      "CPU times: user 32min 7s, sys: 9min 22s, total: 41min 30s\n",
      "Wall time: 19min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predict_test, predict_train = model.fit_predict(timeout=1500, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:11:28.827682Z",
     "start_time": "2020-05-07T01:11:28.808642Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.33952545, 0.48657555, 0.62185893, 0.45343977, 0.07799106])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "predict_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test AUC:  0.8083\n"
     ]
    }
   ],
   "source": [
    "print('Test AUC: ', round(sklearn.metrics.roc_auc_score(y_test, predict_test),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   score_opt  model_score  score_std    model_name  \\\n",
       "0     0.7704       0.8097   0.039278  RandomForest   \n",
       "1     0.7703       0.8105   0.040204  RandomForest   \n",
       "2     0.7699       0.8097   0.039843  RandomForest   \n",
       "3     0.7695       0.8088   0.039275  RandomForest   \n",
       "4     0.7626       0.7688   0.006243   LinearModel   \n",
       "5     0.7626       0.7689   0.006349   LinearModel   \n",
       "\n",
       "                                         model_param wrapper_params  \\\n",
       "0  {'verbose': 0, 'random_state': 42, 'n_jobs': -...             {}   \n",
       "1  {'verbose': 0, 'random_state': 42, 'n_jobs': -...             {}   \n",
       "2  {'verbose': 0, 'random_state': 42, 'n_jobs': -...             {}   \n",
       "3  {'verbose': 0, 'random_state': 42, 'n_jobs': -...             {}   \n",
       "4   {'fit_intercept': False, 'C': 72.39799446110504}             {}   \n",
       "5   {'fit_intercept': False, 'C': 88.24233739381233}             {}   \n",
       "\n",
       "                                        cat_encoders  \\\n",
       "0  [OneHotEncoder, HelmertEncoder, HashingEncoder...   \n",
       "1  [OneHotEncoder, HelmertEncoder, HashingEncoder...   \n",
       "2  [OneHotEncoder, HelmertEncoder, HashingEncoder...   \n",
       "3  [OneHotEncoder, HelmertEncoder, HashingEncoder...   \n",
       "4  [OneHotEncoder, HelmertEncoder, HashingEncoder...   \n",
       "5  [OneHotEncoder, HelmertEncoder, HashingEncoder...   \n",
       "\n",
       "                                             columns  cv_folds  \n",
       "0  (credit_amount, OneHotEncoder_personal_status_...        10  \n",
       "1  (credit_amount, OneHotEncoder_personal_status_...        10  \n",
       "2  (credit_amount, OneHotEncoder_personal_status_...        10  \n",
       "3  (credit_amount, OneHotEncoder_personal_status_...        10  \n",
       "4  (duration, age, num_dependents, OneHotEncoder_...         5  \n",
       "5  (duration, age, num_dependents, OneHotEncoder_...         5  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score_opt</th>\n      <th>model_score</th>\n      <th>score_std</th>\n      <th>model_name</th>\n      <th>model_param</th>\n      <th>wrapper_params</th>\n      <th>cat_encoders</th>\n      <th>columns</th>\n      <th>cv_folds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.7704</td>\n      <td>0.8097</td>\n      <td>0.039278</td>\n      <td>RandomForest</td>\n      <td>{'verbose': 0, 'random_state': 42, 'n_jobs': -...</td>\n      <td>{}</td>\n      <td>[OneHotEncoder, HelmertEncoder, HashingEncoder...</td>\n      <td>(credit_amount, OneHotEncoder_personal_status_...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.7703</td>\n      <td>0.8105</td>\n      <td>0.040204</td>\n      <td>RandomForest</td>\n      <td>{'verbose': 0, 'random_state': 42, 'n_jobs': -...</td>\n      <td>{}</td>\n      <td>[OneHotEncoder, HelmertEncoder, HashingEncoder...</td>\n      <td>(credit_amount, OneHotEncoder_personal_status_...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.7699</td>\n      <td>0.8097</td>\n      <td>0.039843</td>\n      <td>RandomForest</td>\n      <td>{'verbose': 0, 'random_state': 42, 'n_jobs': -...</td>\n      <td>{}</td>\n      <td>[OneHotEncoder, HelmertEncoder, HashingEncoder...</td>\n      <td>(credit_amount, OneHotEncoder_personal_status_...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.7695</td>\n      <td>0.8088</td>\n      <td>0.039275</td>\n      <td>RandomForest</td>\n      <td>{'verbose': 0, 'random_state': 42, 'n_jobs': -...</td>\n      <td>{}</td>\n      <td>[OneHotEncoder, HelmertEncoder, HashingEncoder...</td>\n      <td>(credit_amount, OneHotEncoder_personal_status_...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.7626</td>\n      <td>0.7688</td>\n      <td>0.006243</td>\n      <td>LinearModel</td>\n      <td>{'fit_intercept': False, 'C': 72.39799446110504}</td>\n      <td>{}</td>\n      <td>[OneHotEncoder, HelmertEncoder, HashingEncoder...</td>\n      <td>(duration, age, num_dependents, OneHotEncoder_...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.7626</td>\n      <td>0.7689</td>\n      <td>0.006349</td>\n      <td>LinearModel</td>\n      <td>{'fit_intercept': False, 'C': 88.24233739381233}</td>\n      <td>{}</td>\n      <td>[OneHotEncoder, HelmertEncoder, HashingEncoder...</td>\n      <td>(duration, age, num_dependents, OneHotEncoder_...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model.stack_models_cfgs"
   ]
  },
  {
   "source": [
    "# Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((430, 19), (76, 19))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# https://www.openml.org/d/543\n",
    "dataset = fetch_openml(data_id=543, as_frame=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(dataset.data), \n",
    "                                                    pd.DataFrame(dataset.target), \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=RANDOM_SEED,)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   TOWN  TOWN_ID   TRACT      LON      LAT  MEDV  CMEDV  \\\n",
       "104             Medford     24.0  3395.0 -71.0690  42.2480  20.1   20.1   \n",
       "203              Weston     37.0  3671.0 -71.1990  42.2320  48.5   48.5   \n",
       "381  Boston_East_Boston     79.0   407.0 -71.0410  42.2290  10.9   10.9   \n",
       "489             Chelsea     89.0  1602.0 -71.0228  42.2335   7.0    7.0   \n",
       "69           Wilmington     16.0  3313.0 -71.1110  42.3270  20.9   20.9   \n",
       "..                  ...      ...     ...      ...      ...   ...    ...   \n",
       "106             Medford     24.0  3397.0 -71.0622  42.2431  19.5   19.5   \n",
       "270              Dedham     46.0  4022.0 -71.0870  42.1410  21.1   21.1   \n",
       "348             Norwell     69.0  5041.0 -70.9200  42.1016  24.5   24.5   \n",
       "435   Boston_Savin_Hill     83.0   903.0 -71.0460  42.1867  13.4   13.4   \n",
       "102             Medford     24.0  3393.0 -71.0812  42.2515  18.6   18.6   \n",
       "\n",
       "         CRIM    ZN  INDUS CHAS     NOX     RM   AGE     DIS RAD    TAX  \\\n",
       "104   0.13960   0.0   8.56    0  0.5200  6.167  90.0  2.4210   5  384.0   \n",
       "203   0.03510  95.0   2.68    0  0.4161  7.853  33.2  5.1180   4  224.0   \n",
       "381  15.87440   0.0  18.10    0  0.6710  6.545  99.1  1.5192  24  666.0   \n",
       "489   0.18337   0.0  27.74    0  0.6090  5.414  98.3  1.7554   4  711.0   \n",
       "69    0.12816  12.5   6.07    0  0.4090  5.885  33.0  6.4980   4  345.0   \n",
       "..        ...   ...    ...  ...     ...    ...   ...     ...  ..    ...   \n",
       "106   0.17120   0.0   8.56    0  0.5200  5.836  91.9  2.2110   5  384.0   \n",
       "270   0.29916  20.0   6.96    0  0.4640  5.856  42.1  4.4290   3  223.0   \n",
       "348   0.01501  80.0   2.01    0  0.4350  6.635  29.7  8.3440   4  280.0   \n",
       "435  11.16040   0.0  18.10    0  0.7400  6.629  94.6  2.1247  24  666.0   \n",
       "102   0.22876   0.0   8.56    0  0.5200  6.405  85.4  2.7147   5  384.0   \n",
       "\n",
       "     PTRATIO       B  \n",
       "104     20.9  392.69  \n",
       "203     14.7  392.78  \n",
       "381     20.2  396.90  \n",
       "489     20.1  344.05  \n",
       "69      18.9  396.90  \n",
       "..       ...     ...  \n",
       "106     20.9  395.67  \n",
       "270     18.6  388.65  \n",
       "348     17.0  390.94  \n",
       "435     20.2  109.85  \n",
       "102     20.9   70.80  \n",
       "\n",
       "[430 rows x 19 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TOWN</th>\n      <th>TOWN_ID</th>\n      <th>TRACT</th>\n      <th>LON</th>\n      <th>LAT</th>\n      <th>MEDV</th>\n      <th>CMEDV</th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>104</th>\n      <td>Medford</td>\n      <td>24.0</td>\n      <td>3395.0</td>\n      <td>-71.0690</td>\n      <td>42.2480</td>\n      <td>20.1</td>\n      <td>20.1</td>\n      <td>0.13960</td>\n      <td>0.0</td>\n      <td>8.56</td>\n      <td>0</td>\n      <td>0.5200</td>\n      <td>6.167</td>\n      <td>90.0</td>\n      <td>2.4210</td>\n      <td>5</td>\n      <td>384.0</td>\n      <td>20.9</td>\n      <td>392.69</td>\n    </tr>\n    <tr>\n      <th>203</th>\n      <td>Weston</td>\n      <td>37.0</td>\n      <td>3671.0</td>\n      <td>-71.1990</td>\n      <td>42.2320</td>\n      <td>48.5</td>\n      <td>48.5</td>\n      <td>0.03510</td>\n      <td>95.0</td>\n      <td>2.68</td>\n      <td>0</td>\n      <td>0.4161</td>\n      <td>7.853</td>\n      <td>33.2</td>\n      <td>5.1180</td>\n      <td>4</td>\n      <td>224.0</td>\n      <td>14.7</td>\n      <td>392.78</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>Boston_East_Boston</td>\n      <td>79.0</td>\n      <td>407.0</td>\n      <td>-71.0410</td>\n      <td>42.2290</td>\n      <td>10.9</td>\n      <td>10.9</td>\n      <td>15.87440</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0</td>\n      <td>0.6710</td>\n      <td>6.545</td>\n      <td>99.1</td>\n      <td>1.5192</td>\n      <td>24</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>396.90</td>\n    </tr>\n    <tr>\n      <th>489</th>\n      <td>Chelsea</td>\n      <td>89.0</td>\n      <td>1602.0</td>\n      <td>-71.0228</td>\n      <td>42.2335</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>0.18337</td>\n      <td>0.0</td>\n      <td>27.74</td>\n      <td>0</td>\n      <td>0.6090</td>\n      <td>5.414</td>\n      <td>98.3</td>\n      <td>1.7554</td>\n      <td>4</td>\n      <td>711.0</td>\n      <td>20.1</td>\n      <td>344.05</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>Wilmington</td>\n      <td>16.0</td>\n      <td>3313.0</td>\n      <td>-71.1110</td>\n      <td>42.3270</td>\n      <td>20.9</td>\n      <td>20.9</td>\n      <td>0.12816</td>\n      <td>12.5</td>\n      <td>6.07</td>\n      <td>0</td>\n      <td>0.4090</td>\n      <td>5.885</td>\n      <td>33.0</td>\n      <td>6.4980</td>\n      <td>4</td>\n      <td>345.0</td>\n      <td>18.9</td>\n      <td>396.90</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>Medford</td>\n      <td>24.0</td>\n      <td>3397.0</td>\n      <td>-71.0622</td>\n      <td>42.2431</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>0.17120</td>\n      <td>0.0</td>\n      <td>8.56</td>\n      <td>0</td>\n      <td>0.5200</td>\n      <td>5.836</td>\n      <td>91.9</td>\n      <td>2.2110</td>\n      <td>5</td>\n      <td>384.0</td>\n      <td>20.9</td>\n      <td>395.67</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>Dedham</td>\n      <td>46.0</td>\n      <td>4022.0</td>\n      <td>-71.0870</td>\n      <td>42.1410</td>\n      <td>21.1</td>\n      <td>21.1</td>\n      <td>0.29916</td>\n      <td>20.0</td>\n      <td>6.96</td>\n      <td>0</td>\n      <td>0.4640</td>\n      <td>5.856</td>\n      <td>42.1</td>\n      <td>4.4290</td>\n      <td>3</td>\n      <td>223.0</td>\n      <td>18.6</td>\n      <td>388.65</td>\n    </tr>\n    <tr>\n      <th>348</th>\n      <td>Norwell</td>\n      <td>69.0</td>\n      <td>5041.0</td>\n      <td>-70.9200</td>\n      <td>42.1016</td>\n      <td>24.5</td>\n      <td>24.5</td>\n      <td>0.01501</td>\n      <td>80.0</td>\n      <td>2.01</td>\n      <td>0</td>\n      <td>0.4350</td>\n      <td>6.635</td>\n      <td>29.7</td>\n      <td>8.3440</td>\n      <td>4</td>\n      <td>280.0</td>\n      <td>17.0</td>\n      <td>390.94</td>\n    </tr>\n    <tr>\n      <th>435</th>\n      <td>Boston_Savin_Hill</td>\n      <td>83.0</td>\n      <td>903.0</td>\n      <td>-71.0460</td>\n      <td>42.1867</td>\n      <td>13.4</td>\n      <td>13.4</td>\n      <td>11.16040</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0</td>\n      <td>0.7400</td>\n      <td>6.629</td>\n      <td>94.6</td>\n      <td>2.1247</td>\n      <td>24</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>109.85</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>Medford</td>\n      <td>24.0</td>\n      <td>3393.0</td>\n      <td>-71.0812</td>\n      <td>42.2515</td>\n      <td>18.6</td>\n      <td>18.6</td>\n      <td>0.22876</td>\n      <td>0.0</td>\n      <td>8.56</td>\n      <td>0</td>\n      <td>0.5200</td>\n      <td>6.405</td>\n      <td>85.4</td>\n      <td>2.7147</td>\n      <td>5</td>\n      <td>384.0</td>\n      <td>20.9</td>\n      <td>70.80</td>\n    </tr>\n  </tbody>\n</table>\n<p>430 rows × 19 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Source X_train shape:  (430, 19) | X_test shape:  (76, 19)\n",
      "##################################################\n",
      "Auto detect cat features:  0\n",
      "> Start preprocessing Data\n",
      "> Generate cat encodet features\n",
      " +  102  Features from  OneHotEncoder\n",
      " +  100  Features from  HelmertEncoder\n",
      " +  100  Features from  HashingEncoder\n",
      " +  3  Features from  FrequencyEncoder\n",
      "> Generate Frequency Encode num features\n",
      " +  16  Frequency Encode Num Features \n",
      "> Clean Nans in num features\n",
      "> Generate interaction Num Features\n",
      " +  480  Interaction Features\n",
      "> Normalization Features\n",
      "##################################################\n",
      "> Total Features:  817\n",
      "##################################################\n",
      "New X_train shape:  (430, 817) | X_test shape:  (76, 817)\n"
     ]
    }
   ],
   "source": [
    "model = AutoMLRegressor(X_train, y_train, X_test, random_state=RANDOM_SEED, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "__________________________________________________\n",
      "Step 1: Model 0\n",
      "__________________________________________________\n",
      "100%|██████████| 1/1 [00:53<00:00, 53.13s/it]\n",
      "--------------------------------------------------\n",
      "Model 1\n",
      "One iteration takes ~ 7.6 sec\n",
      "> Start Auto calibration parameters\n",
      "\u001b[32m[I 2020-11-23 09:53:46,319]\u001b[0m A new study created in memory with name: no-name-8d331de2-19cd-4819-aaf2-353b151e5845\u001b[0m\n",
      "> Start optimization with the parameters:\n",
      "CV_Folds =  5\n",
      "Score_CV_Folds =  2\n",
      "Feature_Selection =  True\n",
      "Opt_lvl =  1\n",
      "Cold_start =  55.0\n",
      "Early_stoping =  100\n",
      "Metric =  mean_squared_error\n",
      "Direction =  minimize\n",
      "##################################################\n",
      "Default model OptScore = 15.8712\n",
      "Optimize: : 113it [14:08,  7.51s/it,  | Model: LightGBM | OptScore: 11.4918 | Best mean_squared_error: 10.2078 +- 1.284002]\n",
      "\n",
      " Predict from Models_1\n",
      "100%|██████████| 3/3 [00:21<00:00,  7.04s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      " > Calc predict policy on Models_1:\n",
      " | posible_repeats:  4  | stack_top:  4  | n_repeats:  1\n",
      " 25%|██▌       | 1/4 [00:31<01:33, 31.17s/it]\n",
      " Mean Score mean_squared_error on 5 Folds: 10.9596 std: 2.033629\n",
      " 50%|█████     | 2/4 [00:58<00:59, 29.92s/it]\n",
      " Mean Score mean_squared_error on 5 Folds: 10.4869 std: 2.909482\n",
      " 75%|███████▌  | 3/4 [01:29<00:30, 30.43s/it]\n",
      " Mean Score mean_squared_error on 5 Folds: 10.4684 std: 2.321321\n",
      "100%|██████████| 4/4 [02:28<00:00, 37.12s/it]\n",
      " Mean Score mean_squared_error on 5 Folds: 10.9694 std: 2.527378\n",
      "\n",
      " Models_1 Mean mean_squared_error Score Train:  10.29\n",
      "--------------------------------------------------\n",
      "Model 2\n",
      "\n",
      "One iteration takes ~ 8.3 sec\n",
      "> Start Auto calibration parameters\n",
      "> Start optimization with the parameters:\n",
      "CV_Folds =  5\n",
      "Score_CV_Folds =  1\n",
      "Feature_Selection =  True\n",
      "Opt_lvl =  1\n",
      "Cold_start =  10\n",
      "Early_stoping =  50\n",
      "Metric =  mean_squared_error\n",
      "Direction =  minimize\n",
      "##################################################\n",
      "Default model OptScore = 15.8712\n",
      "Optimize: : 98it [03:21,  2.05s/it,  | Model: MLP | OptScore: 11.7292 | Best mean_squared_error: 11.7292 ]\n",
      "\n",
      " Predict from Models_2\n",
      " 50%|█████     | 1/2 [00:11<00:11, 11.43s/it]\n",
      " Mean Score mean_squared_error on 5 Folds: 11.0699 std: 1.158163\n",
      "100%|██████████| 2/2 [00:21<00:00, 10.65s/it]\n",
      " Mean Score mean_squared_error on 5 Folds: 11.796 std: 2.594957\n",
      "\n",
      " Models_2 Mean mean_squared_error Score Train:  10.8199\n",
      "--------------------------------------------------\n",
      "\n",
      " Blend Models mean_squared_error Score Train:  9.4778\n",
      "__________________________________________________\n",
      "Step 2: Stacking\n",
      "__________________________________________________\n",
      "\n",
      "\n",
      " Final Model mean_squared_error Score Train:  9.4778\n"
     ]
    }
   ],
   "source": [
    "predict_test, predict_train = model.fit_predict(timeout=1500, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test MSE:  8.6016\n"
     ]
    }
   ],
   "source": [
    "print('Test MSE: ', round(sklearn.metrics.mean_squared_error(y_test, predict_test),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}