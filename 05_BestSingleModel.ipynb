{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:04:07.223678Z",
     "start_time": "2020-05-07T01:04:07.203114Z"
    }
   },
   "outputs": [],
   "source": [
    "# If you run this notebook on Google Colaboratory, uncomment the below to install automl_alex.\n",
    "#!pip install -q -U automl_alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:05:50.878720Z",
     "start_time": "2020-05-07T01:05:50.874642Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AutoML-Alex version: 1.2.28\n"
     ]
    }
   ],
   "source": [
    "import automl_alex\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import time\n",
    "from automl_alex import DataPrepare\n",
    "from automl_alex import BestSingleModel, BestSingleModelClassifier, BestSingleModelRegressor\n",
    "print('AutoML-Alex version:', automl_alex.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:05:52.553896Z",
     "start_time": "2020-05-07T01:05:52.549132Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:05:55.127924Z",
     "start_time": "2020-05-07T01:05:55.037616Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  age         workclass    fnlwgt  education  education-num  \\\n",
       "0   2         State-gov   77516.0  Bachelors           13.0   \n",
       "1   3  Self-emp-not-inc   83311.0  Bachelors           13.0   \n",
       "2   2           Private  215646.0    HS-grad            9.0   \n",
       "3   3           Private  234721.0       11th            7.0   \n",
       "4   1           Private  338409.0  Bachelors           13.0   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "  capitalgain capitalloss hoursperweek native-country  \n",
       "0           1           0            2  United-States  \n",
       "1           0           0            0  United-States  \n",
       "2           0           0            2  United-States  \n",
       "3           0           0            2  United-States  \n",
       "4           0           0            2           Cuba  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capitalgain</th>\n      <th>capitalloss</th>\n      <th>hoursperweek</th>\n      <th>native-country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>State-gov</td>\n      <td>77516.0</td>\n      <td>Bachelors</td>\n      <td>13.0</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311.0</td>\n      <td>Bachelors</td>\n      <td>13.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Private</td>\n      <td>215646.0</td>\n      <td>HS-grad</td>\n      <td>9.0</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Private</td>\n      <td>234721.0</td>\n      <td>11th</td>\n      <td>7.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Private</td>\n      <td>338409.0</td>\n      <td>Bachelors</td>\n      <td>13.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Cuba</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "# https://www.openml.org/d/179\n",
    "dataset = fetch_openml(data_id=179, as_frame=True)\n",
    "dataset.target = dataset.target.astype('category').cat.codes\n",
    "dataset.data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:05:56.756465Z",
     "start_time": "2020-05-07T01:05:56.734220Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((36631, 14), (12211, 14))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, \n",
    "                                                    dataset.target,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=RANDOM_SEED,)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "source": [
    "## BestSingleModel"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12:57:50 | > Start Fit Base Model\n",
      "12:58:35 | > DATA PREPROC\n",
      "12:58:35 | Source data shape: (36631, 14)\n",
      "12:58:35 | ##################################################\n",
      "12:58:35 | ! START preprocessing Data\n",
      "12:58:35 | - Auto detect cat features: 12\n",
      "12:58:35 | > Binary Features\n",
      "12:58:35 | > Clean Categorical Features\n",
      "12:58:36 | > Transform Categorical Features.\n",
      "12:58:36 |  - Encoder: OneHotEncoder ADD features: 135\n",
      "12:58:37 |  - Encoder: CountEncoder ADD features: 12\n",
      "12:58:37 | > CleanOutliers\n",
      "12:58:37 | Num of outlier detected: 231 in Feature education-num\n",
      "12:58:37 | Proportion of outlier detected: 0.6 %\n",
      "12:58:37 | Num of outlier detected: 527 in Feature fnlwgt\n",
      "12:58:37 | Proportion of outlier detected: 1.4 %\n",
      "12:58:37 |   No nans features\n",
      "12:58:37 | > Generate interaction Num Features\n",
      "12:58:37 |  ADD features: 5\n",
      "12:58:37 | > Normalization Features\n",
      "12:58:37 | ##################################################\n",
      "12:58:37 | Final data shape: (36631, 168)\n",
      "12:58:37 | Total ADD columns: 154\n",
      "12:58:37 | ##################################################\n",
      "12:58:37 | ##################################################\n",
      "12:58:37 | > Start Fit Models 3\n",
      "12:58:37 | ##################################################\n",
      "12:58:59 | > DATA PREPROC\n",
      "12:58:59 | Source data shape: (36631, 14)\n",
      "12:58:59 | ##################################################\n",
      "12:58:59 | ! START preprocessing Data\n",
      "12:58:59 | - Auto detect cat features: 12\n",
      "12:58:59 | > Binary Features\n",
      "12:58:59 | > Clean Categorical Features\n",
      "12:58:59 | > Transform Categorical Features.\n",
      "12:59:00 |  - Encoder: HelmertEncoder ADD features: 123\n",
      "12:59:00 |  - Encoder: CountEncoder ADD features: 12\n",
      "12:59:00 |  - Encoder: HashingEncoder ADD features: 12\n",
      "12:59:00 | > CleanOutliers\n",
      "12:59:00 | Num of outlier detected: 231 in Feature education-num\n",
      "12:59:00 | Proportion of outlier detected: 0.6 %\n",
      "12:59:00 | Num of outlier detected: 527 in Feature fnlwgt\n",
      "12:59:00 | Proportion of outlier detected: 1.4 %\n",
      "12:59:00 |   No nans features\n",
      "12:59:00 | > Generate interaction Num Features\n",
      "12:59:00 |  ADD features: 5\n",
      "12:59:00 | ##################################################\n",
      "12:59:00 | Final data shape: (36631, 168)\n",
      "12:59:00 | Total ADD columns: 154\n",
      "12:59:00 | ##################################################\n",
      "12:59:00 | ##################################################\n",
      "12:59:00 | > Start Fit Models 4\n",
      "12:59:20 | ##################################################\n",
      "12:59:20 | > Start Fit Models 5\n",
      "12:59:20 | ##################################################\n",
      "12:59:20 | ##################################################\n",
      "12:59:20 | > Step 1: calc parameters and pruned score: get test 10 trials\n",
      "13:01:47 |  One iteration takes ~ 14.7 sec\n",
      "13:01:47 |  Possible iters ~ 30.0\n",
      "13:01:48 | ! Not enough time to find the optimal parameters. \n",
      "                     Possible iters < 100. \n",
      "                     Please, Increase the 'timeout' parameter for normal optimization.\n",
      "13:01:48 | --------------------------------------------------\n",
      "13:01:48 |   Pruned Threshold Score: 0.8966\n",
      "13:01:48 | ##################################################\n",
      "13:01:48 | > Step 2: Full opt with Threshold Score Pruner\n",
      "13:01:48 | ##################################################\n",
      "13:01:48 | > Start optimization with the parameters:\n",
      "13:01:48 | CV_Folds = 10\n",
      "13:01:48 | Score_CV_Folds = 2\n",
      "13:01:48 | Feature_Selection = True\n",
      "13:01:48 | Opt_lvl = 1\n",
      "13:01:48 | Cold_start = 10\n",
      "13:01:48 | Early_stoping = 25\n",
      "13:01:48 | Metric = roc_auc_score\n",
      "13:01:48 | Direction = maximize\n",
      "13:01:48 | ##################################################\n",
      "Optimize: : 46it [07:32,  9.84s/it, | Model: LightGBM | OptScore: 0.9114 | Best roc_auc_score: 0.9124 ]\n",
      "13:09:20 | > Finish Opt!\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "13:09:43 | Best Score: 0.9124 roc_auc_score\n",
      "13:09:43 | Save Model\n",
      "13:09:43 | Save Model\n",
      "13:09:43 | Save Model\n",
      "13:09:43 | Save Model\n",
      "13:09:43 | Save Model\n",
      "13:09:43 | Save Model\n",
      "13:09:43 | Save Model\n",
      "13:09:43 | Save Model\n",
      "13:09:43 | Save Model\n",
      "13:09:43 | Save Model\n",
      "Save model\n",
      "13:09:44 | ##################################################\n",
      "13:09:44 | > Finish!\n"
     ]
    }
   ],
   "source": [
    "model = BestSingleModelClassifier(\n",
    "    models_names = ['LightGBM', 'ExtraTrees', 'RandomForest', 'XGBoost'],\n",
    "    auto_parameters=True,\n",
    "    feature_selection=True,\n",
    "    random_state=RANDOM_SEED,)\n",
    "model.fit(X_train, y_train, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Finished loading model, total used 300 iterations\n",
      "Load CrossValidation\n",
      "Load CrossValidation\n"
     ]
    }
   ],
   "source": [
    "predicts = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test AUC:  0.9137\n"
     ]
    }
   ],
   "source": [
    "print('Test AUC: ', round(sklearn.metrics.roc_auc_score(y_test, predicts),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_model_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select Features \n",
    "# if feature_selection=True\n",
    "model.select_columns[:5]"
   ]
  },
  {
   "source": [
    "## Save & Load"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AutoML_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = BestSingleModelClassifier(random_state=RANDOM_SEED,)\n",
    "model_new = model_new.load('AutoML_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model_new.predict(X_test)\n",
    "print('Test AUC: ', round(sklearn.metrics.roc_auc_score(y_test, predicts),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}