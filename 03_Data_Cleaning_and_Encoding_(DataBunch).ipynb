{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:23:49.057981Z",
     "start_time": "2020-05-07T04:23:49.053936Z"
    }
   },
   "outputs": [],
   "source": [
    "# If you run this notebook on Google Colaboratory, uncomment the below to install automl_alex.\n",
    "#!pip install -U -q automl-alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:23:53.125987Z",
     "start_time": "2020-05-07T04:23:49.634140Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "#import automl_alex\n",
    "#from automl_alex import LightGBMClassifier, DataBunch\n",
    "\n",
    "#print(automl_alex.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:23:53.136324Z",
     "start_time": "2020-05-07T04:23:53.129088Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:23:54.266953Z",
     "start_time": "2020-05-07T04:23:53.244733Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  age         workclass    fnlwgt  education  education-num  \\\n",
       "0   2         State-gov   77516.0  Bachelors           13.0   \n",
       "1   3  Self-emp-not-inc   83311.0  Bachelors           13.0   \n",
       "2   2           Private  215646.0    HS-grad            9.0   \n",
       "3   3           Private  234721.0       11th            7.0   \n",
       "4   1           Private  338409.0  Bachelors           13.0   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "  capitalgain capitalloss hoursperweek native-country  \n",
       "0           1           0            2  United-States  \n",
       "1           0           0            0  United-States  \n",
       "2           0           0            2  United-States  \n",
       "3           0           0            2  United-States  \n",
       "4           0           0            2           Cuba  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capitalgain</th>\n      <th>capitalloss</th>\n      <th>hoursperweek</th>\n      <th>native-country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>State-gov</td>\n      <td>77516.0</td>\n      <td>Bachelors</td>\n      <td>13.0</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311.0</td>\n      <td>Bachelors</td>\n      <td>13.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Private</td>\n      <td>215646.0</td>\n      <td>HS-grad</td>\n      <td>9.0</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Private</td>\n      <td>234721.0</td>\n      <td>11th</td>\n      <td>7.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Private</td>\n      <td>338409.0</td>\n      <td>Bachelors</td>\n      <td>13.0</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Cuba</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "dataset = fetch_openml(name='adult', version=1, as_frame=True)\n",
    "# convert target to binary\n",
    "dataset.target = dataset.target.astype('category').cat.codes\n",
    "dataset.data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:23:54.292030Z",
     "start_time": "2020-05-07T04:23:54.276548Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((39073, 14), (9769, 14))"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, \n",
    "                                                    dataset.target,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=RANDOM_SEED,)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning (DataBunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from category_encoders import HashingEncoder, SumEncoder, PolynomialEncoder, BackwardDifferenceEncoder \n",
    "from category_encoders import OneHotEncoder, HelmertEncoder, OrdinalEncoder, BaseNEncoder\n",
    "from category_encoders import TargetEncoder, CatBoostEncoder, WOEEncoder, JamesSteinEncoder\n",
    "from category_encoders.count import CountEncoder\n",
    "\n",
    "################################################################\n",
    "            #               Simple Encoders \n",
    "            #      (do not use information about target)\n",
    "################################################################\n",
    "\n",
    "cat_encoders_names = {\n",
    "                'HashingEncoder': HashingEncoder,\n",
    "                'SumEncoder': SumEncoder,\n",
    "                'BackwardDifferenceEncoder': BackwardDifferenceEncoder,\n",
    "                'OneHotEncoder': OneHotEncoder,\n",
    "                'HelmertEncoder': HelmertEncoder,\n",
    "                'OrdinalEncoder': OrdinalEncoder,\n",
    "                'BaseNEncoder': BaseNEncoder,\n",
    "                'CountEncoder': CountEncoder,\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "################################################################\n",
    "            #                Target Encoders\n",
    "################################################################\n",
    "\n",
    "target_encoders_names = {\n",
    "                'TargetEncoder': TargetEncoder,\n",
    "                'CatBoostEncoder': CatBoostEncoder,\n",
    "                'WOEEncoder': WOEEncoder,\n",
    "                'JamesSteinEncoder': JamesSteinEncoder,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "\n",
    "\n",
    "# disable chained assignments\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "\n",
    "class CleanNans(object):\n",
    "    \"\"\"\n",
    "    Сlass for cleaning Nans\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, method='median'):\n",
    "        \"\"\"\n",
    "        Fill Nans and add column, that there were nans in this column\n",
    "        \n",
    "        Args:\n",
    "            method : {'median', 'mean',}\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "\n",
    "    def fit(self, data, cols=None):\n",
    "        \"\"\"\n",
    "        Fit fillna.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame, shape (n_samples, n_features)): the input data\n",
    "            cols list() features: the input data\n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        if cols is not None:\n",
    "            data = data[cols]\n",
    "        \n",
    "        data = data._get_numeric_data()\n",
    "        \n",
    "        self.nan_columns = list(data.columns[data.isnull().sum() > 0])\n",
    "        if not self.nan_columns:     \n",
    "            print('No nans features')\n",
    "\n",
    "        if self.method is 'median':\n",
    "            self.fill_value = data.median()\n",
    "        elif self.method is 'mean':\n",
    "            self.fill_value = data.mean()\n",
    "        else:\n",
    "            raise ValueError('Wrong fill method')\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data, cols=None):\n",
    "        \"\"\"Transforms the dataset.\n",
    "        Args:\n",
    "            data (pd.DataFrame, shape (n_samples, n_features)): the input data\n",
    "            cols list() features: the input data\n",
    "        Returns:\n",
    "            pandas.Dataframe of shape = (n_train, n_features)\n",
    "                The train dataset with no missing values.\n",
    "        \"\"\"\n",
    "        if cols is not None:\n",
    "            data = data[cols]\n",
    "\n",
    "        if self.nan_columns:\n",
    "            for nan_column in self.nan_columns:\n",
    "                data[nan_column+'_isNAN'] = pd.isna(data[nan_column]).astype('uint8')\n",
    "            \n",
    "            data.fillna(self.fill_value, inplace=True)\n",
    "        else:\n",
    "            raise ValueError('No nans features')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def fit_transform(self, data, cols=None):\n",
    "        \"\"\"Fit and transforms the dataset.\n",
    "        Args:\n",
    "            data (pd.DataFrame, shape (n_samples, n_features)): the input data\n",
    "            cols list() features: the input data\n",
    "        Returns:\n",
    "            pandas.Dataframe of shape = (n_train, n_features)\n",
    "                The train dataset with no missing values.\n",
    "        \"\"\"\n",
    "        self.fit(data, cols)\n",
    "\n",
    "        return self.transform(data)\n",
    "\n",
    "class DataPrepare(object):\n",
    "    \"\"\"\n",
    "    Сlass for cleaning, encoding and processing your dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                cat_features=None,\n",
    "                clean_and_encod_data=True,\n",
    "                cat_encoder_names=['HelmertEncoder','CountEncoder'],\n",
    "                clean_nan=True,\n",
    "                num_generator_features=True,\n",
    "                #group_generator_features=False,\n",
    "                #frequency_enc_num_features=False,\n",
    "                random_state=42,\n",
    "                verbose=1):\n",
    "        \"\"\"\n",
    "        Description of __init__\n",
    "\n",
    "        Args:\n",
    "            cat_features=None (list or None): \n",
    "            clean_and_encod_data=True (undefined):\n",
    "            cat_encoder_names=None (list or None):\n",
    "            clean_nan=True (undefined):\n",
    "            num_generator_features=True (undefined):\n",
    "            random_state=42 (undefined):\n",
    "        \"\"\"\n",
    "        self.random_state = random_state\n",
    "        self.cat_encoder_names = cat_encoder_names\n",
    "        self.verbose = verbose\n",
    "        self._clean_and_encod_data = clean_and_encod_data\n",
    "        self._clean_nan = clean_nan\n",
    "        self._num_generator_features = num_generator_features\n",
    "        self.cat_features = cat_features\n",
    "\n",
    "        self.binary_encoder = None\n",
    "        self.clean_nan_encoder = None\n",
    "        self.cat_clean_ord_encoder = None\n",
    "\n",
    "        self.fit_cat_encoders={}\n",
    "\n",
    "    def check_data_format(self, data):\n",
    "        \"\"\"\n",
    "        Description of check_data_format:\n",
    "            Check that data is not pd.DataFrame or empty\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame, shape (n_samples, n_features)): the input data\n",
    "        Return:\n",
    "            True or Exception\n",
    "        \"\"\"\n",
    "        if (not isinstance(data, pd.DataFrame)) or data.empty:\n",
    "            raise Exception(\"data is not pd.DataFrame or empty\")\n",
    "\n",
    "    def check_num_nans(self, data):\n",
    "        \"\"\"\n",
    "        Description of check_num_nans:\n",
    "            Check Nans in numeric features in data \n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame, shape (n_samples, n_features)): the input data\n",
    "        Return:\n",
    "            True or Exception\n",
    "        \"\"\"\n",
    "        data = data._get_numeric_data()\n",
    "        return(len(list(data.columns[data.isnull().sum() > 0])) > 0)\n",
    "\n",
    "    def auto_detect_cat_features(self, data):\n",
    "        \"\"\"\n",
    "        Description of _auto_detect_cat_features:\n",
    "            Auto-detection categorical_features by simple rule:\n",
    "            categorical feature == if feature nunique low 1% of data\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): dataset\n",
    "            \n",
    "        Returns:\n",
    "            cat_features (list): columns names cat features\n",
    "        \n",
    "        \"\"\"\n",
    "        #object_features = list(data.columns[data.dtypes == 'object'])\n",
    "        cat_features = data.columns[(data.nunique(dropna=False) < len(data)//100) & \\\n",
    "            (data.nunique(dropna=False) >2)]\n",
    "        if len(cat_features) < 1:\n",
    "            cat_features = None\n",
    "        #cat_features = list(set([*object_features, *cat_features]))\n",
    "        return(cat_features)\n",
    "    \n",
    "    def gen_numeric_interaction_features(self, \n",
    "                                        df, \n",
    "                                        columns, \n",
    "                                        operations=['/','*','-','+'],) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Description of numeric_interaction_terms:\n",
    "            Numerical interaction generator features: A/B, A*B, A-B,\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame):\n",
    "            columns (list): num columns names\n",
    "            operations (list): operations type\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame\n",
    "\n",
    "        \"\"\"\n",
    "        fe_df = pd.DataFrame()\n",
    "        for c in combinations(columns,2):\n",
    "            if '/' in operations:\n",
    "                fe_df['{}_/_{}'.format(c[0], c[1]) ] = (df[c[0]]*1.) / df[c[1]]\n",
    "            if '*' in operations:\n",
    "                fe_df['{}_*_{}'.format(c[0], c[1]) ] = df[c[0]] * df[c[1]]\n",
    "            if '-' in operations:\n",
    "                fe_df['{}_-_{}'.format(c[0], c[1]) ] = df[c[0]] - df[c[1]]\n",
    "            if '+' in operations:\n",
    "                fe_df['{}_+_{}'.format(c[0], c[1]) ] = df[c[0]] + df[c[1]]\n",
    "        return(fe_df)\n",
    "\n",
    "    def fit(self, data,):\n",
    "        \"\"\"\n",
    "        Fit DataPrepare.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame, shape (n_samples, n_features)): \n",
    "                the input data\n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        ########### check_data_format ######################\n",
    "        self.check_data_format(data)\n",
    "\n",
    "        if self.verbose > 0:   \n",
    "            print('Source data shape: ', data.shape,)\n",
    "            print('#'*50)\n",
    "            print('! START FIT preprocessing Data')\n",
    "\n",
    "        data = data.reset_index(drop=True)\n",
    "        ########### Detect type of features ######################\n",
    "\n",
    "        if self.cat_features is None:\n",
    "            self.cat_features = self.auto_detect_cat_features(data)\n",
    "            if self.verbose > 0:\n",
    "                print('- Auto detect cat features: ', len(self.cat_features))\n",
    "\n",
    "        self.binary_features = data.columns[data.nunique(dropna=False) <= 2]\n",
    "        self.num_features = list(set(data.select_dtypes('number').columns) - set(self.binary_features))\n",
    "\n",
    "\n",
    "        ########### Binary Features ######################\n",
    "        if len(self.binary_features) > 0:\n",
    "            if self.verbose > 0:\n",
    "                    print('> Binary Features')\n",
    "\n",
    "            self.binary_encoder = OrdinalEncoder()\n",
    "            self.binary_encoder = self.binary_encoder.fit(data[self.binary_features])\n",
    "\n",
    "        ########### Categorical Features ######################\n",
    "        if self.cat_features is not None:\n",
    "            # Clean Categorical Features\n",
    "            if self.verbose > 0:\n",
    "                    print('> Clean Categorical Features')\n",
    "            self.cat_clean_ord_encoder = OrdinalEncoder()\n",
    "            self.cat_clean_ord_encoder = self.cat_clean_ord_encoder.fit(data[self.cat_features])\n",
    "            data[self.cat_features] = self.cat_clean_ord_encoder.transform(data[self.cat_features])\n",
    "\n",
    "\n",
    "            # Encode Categorical Features\n",
    "            if self.verbose > 0:\n",
    "                    print('> Encode Categorical Features.')\n",
    "\n",
    "            for cat_encoder_name in self.cat_encoder_names:\n",
    "                if self.verbose > 0:\n",
    "                    print(' +', cat_encoder_name)\n",
    "\n",
    "                if cat_encoder_name not in cat_encoders_names.keys():\n",
    "                    raise Exception(f\"{cat_encoder_name} not support!\")\n",
    "\n",
    "                self.fit_cat_encoders[cat_encoder_name] = cat_encoders_names[cat_encoder_name](cols=self.cat_features, drop_invariant=True)\n",
    "                if cat_encoder_name == 'HashingEncoder':\n",
    "                    self.fit_cat_encoders[cat_encoder_name] = cat_encoders_names[cat_encoder_name](\n",
    "                            n_components=int(np.log(len(data.columns))*1000), \n",
    "                            drop_invariant=True)\n",
    "                \n",
    "                self.fit_cat_encoders[cat_encoder_name] = \\\n",
    "                    self.fit_cat_encoders[cat_encoder_name].fit(data[self.cat_features])\n",
    "\n",
    "        ########### Numerical Features ######################\n",
    "\n",
    "        # CleanNans\n",
    "        if self._clean_nan:\n",
    "            if self.check_num_nans(data):\n",
    "                self.clean_nan_encoder = CleanNans()\n",
    "                self.clean_nan_encoder = self.clean_nan_encoder.fit(data[self.num_features])\n",
    "                if self.verbose:\n",
    "                    print('> CleanNans, total nans columns:', \\\n",
    "                        len(self.clean_nan_encoder.nan_columns))\n",
    "            else:\n",
    "                if self.verbose:\n",
    "                    print('  No nans features')\n",
    "\n",
    "        ########### Final ######################\n",
    "        if self.verbose:\n",
    "            print('#'*50)\n",
    "            print('! END FIT preprocessing Data')\n",
    "        return self\n",
    "\n",
    "    def transform(self, data) -> pd.DataFrame:\n",
    "        \"\"\"Transform dataset.\n",
    "        Args:\n",
    "            data (pd.DataFrame, shape = (n_samples, n_features)): \n",
    "                the input data\n",
    "        Returns:\n",
    "            data (pd.Dataframe, shape = (n_train, n_features)):\n",
    "                The dataset with clean numerical and encoded categorical features.\n",
    "        \"\"\"\n",
    "        if self.verbose > 0:\n",
    "            start_columns = len(data.columns)\n",
    "            print('#'*50)\n",
    "            print('! Start Transform Data')\n",
    "\n",
    "        data = data.reset_index(drop=True)\n",
    "\n",
    "        ########### Binary Features ######################\n",
    "        \n",
    "        if self.binary_encoder:\n",
    "            data[self.binary_features] = self.binary_encoder.transform(data[self.binary_features]).replace(2,0).astype('category')\n",
    "            if self.verbose:\n",
    "                print('> Clean Binary Features')\n",
    "\n",
    "        ########### Categorical Features ######################\n",
    "        if self.cat_features is not None:\n",
    "            # Clean Categorical Features\n",
    "            if self.verbose > 0:\n",
    "                print('> Clean Categorical Features')\n",
    "            data[self.cat_features] = self.cat_clean_ord_encoder.transform(data[self.cat_features])\n",
    "\n",
    "            # Encode Categorical Features\n",
    "            if self.verbose > 0:\n",
    "                print('> Transform Categorical Features.')\n",
    "            for cat_encoder_name in self.cat_encoder_names:\n",
    "                data_encodet = self.fit_cat_encoders[cat_encoder_name].transform(data[self.cat_features])\n",
    "                data_encodet = data_encodet.add_prefix(cat_encoder_name + '_')\n",
    "                if self.verbose > 0:\n",
    "                    print(' - Encoder:', cat_encoder_name, 'ADD features:', len(data_encodet.columns))\n",
    "                data = data.join(data_encodet.reset_index(drop=True))\n",
    "        \n",
    "\n",
    "        ########### Numerical Features ######################\n",
    "        # CleanNans\n",
    "        if self.clean_nan_encoder:\n",
    "            data = self.clean_nan_encoder.transform(data)\n",
    "            if self.verbose:\n",
    "                print('> Clean Nans')\n",
    "\n",
    "        # Generator interaction Num Features\n",
    "        if self._num_generator_features:\n",
    "            if len(self.num_features) > 1:\n",
    "                if self.verbose > 0:\n",
    "                    print('> Generate interaction Num Features')\n",
    "                fe_df = self.gen_numeric_interaction_features(data[self.num_features], \n",
    "                                                            self.num_features,\n",
    "                                                            operations=['/','*','-','+'],)\n",
    "                data = data.join(fe_df.reset_index(drop=True))\n",
    "                if self.verbose > 0:\n",
    "                    print(' ADD features:', fe_df.shape[1],)\n",
    "        \n",
    "        data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        data.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "        ########### Final ######################\n",
    "        if self.verbose > 0:\n",
    "            end_columns = len(data.columns)\n",
    "            print('#'*50)\n",
    "            print('Final data shape: ', data.shape,)\n",
    "            print('Total ADD columns:', end_columns-start_columns)\n",
    "        return data\n",
    "\n",
    "    def fit_transform(self, data,) -> pd.DataFrame:\n",
    "        \"\"\"Fits and transforms the dataset.\n",
    "        Args:\n",
    "            data (pd.DataFrame, shape = (n_samples, n_features)): \n",
    "                the input data\n",
    "        Returns:\n",
    "            data (pd.Dataframe, shape = (n_train, n_features)):\n",
    "                The dataset with clean numerical and encoded categorical features.\n",
    "        \"\"\"\n",
    "        self.fit(data)\n",
    "\n",
    "        return self.transform(data)\n",
    "\n",
    "    def save(self, name):\n",
    "        pickle.dump(self, open(name+'.pkl', 'wb'), protocol=4)\n",
    "\n",
    "    def load(self, name):\n",
    "        return(pickle.load(open(name+'.pkl', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((39073, 14), (9769, 14))"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, \n",
    "                                                    dataset.target,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=RANDOM_SEED,)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = DataPrepare()\n",
    "de = de.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "##################################################\n",
      "! Start Transform Data\n",
      "> Clean Binary Features\n",
      "> Clean Categorical Features\n",
      "> Transform Categorical Features.\n",
      " - Encoder: HelmertEncoder ADD features: 123\n",
      " - Encoder: CountEncoder ADD features: 12\n",
      "> Generate interaction Num Features\n",
      " ADD features: 4\n",
      "##################################################\n",
      "Final data shape:  (39073, 153)\n",
      "Total ADD columns: 139\n"
     ]
    }
   ],
   "source": [
    "X_train = de.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "de.save('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = de.load('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "##################################################\n",
      "! Start Transform Data\n",
      "> Clean Binary Features\n",
      "> Clean Categorical Features\n",
      "> Transform Categorical Features.\n",
      " - Encoder: HelmertEncoder ADD features: 123\n",
      " - Encoder: CountEncoder ADD features: 12\n",
      "> Generate interaction Num Features\n",
      " ADD features: 4\n",
      "##################################################\n",
      "Final data shape:  (9769, 153)\n",
      "Total ADD columns: 139\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      age  workclass    fnlwgt  education  education-num  marital-status  \\\n",
       "0       5          1  423024.0          1            9.0               4   \n",
       "1       5          1  178953.0          3            8.0               4   \n",
       "2       5          3  348986.0          1            9.0               4   \n",
       "3       5          1  218215.0          6           10.0               4   \n",
       "4       4          1  244025.0          1            9.0               4   \n",
       "...   ...        ...       ...        ...            ...             ...   \n",
       "9764    3          4  118614.0          2           14.0               5   \n",
       "9765    5          1  205838.0          1            9.0               4   \n",
       "9766    2          1  194304.0          6           10.0               2   \n",
       "9767    4          4  245724.0          6           10.0               2   \n",
       "9768    2          1  182757.0          1            9.0               1   \n",
       "\n",
       "      occupation  relationship  race sex  ...  CountEncoder_relationship  \\\n",
       "0              6             3     1   1  ...                      10067   \n",
       "1              5             5     1   0  ...                       6122   \n",
       "2             10             4     2   1  ...                       1180   \n",
       "3              5             5     1   0  ...                       6122   \n",
       "4             11             2     5   1  ...                       4059   \n",
       "...          ...           ...   ...  ..  ...                        ...   \n",
       "9764           5             2     1   0  ...                       4059   \n",
       "9765           6             5     1   1  ...                       6122   \n",
       "9766           1             3     2   1  ...                      10067   \n",
       "9767           8             3     1   1  ...                      10067   \n",
       "9768           4             1     1   1  ...                      15748   \n",
       "\n",
       "      CountEncoder_race  CountEncoder_capitalgain  CountEncoder_capitalloss  \\\n",
       "0                 33425                     35788                     37253   \n",
       "1                 33425                     35788                     37253   \n",
       "2                  3734                     35788                     37253   \n",
       "3                 33425                     35788                     37253   \n",
       "4                   374                     35788                     37253   \n",
       "...                 ...                       ...                       ...   \n",
       "9764              33425                     35788                     37253   \n",
       "9765              33425                     35788                     37253   \n",
       "9766               3734                     35788                     37253   \n",
       "9767              33425                     35788                     37253   \n",
       "9768              33425                     35788                     37253   \n",
       "\n",
       "      CountEncoder_hoursperweek  CountEncoder_native-country  \\\n",
       "0                          3582                        35123   \n",
       "1                          3582                        35123   \n",
       "2                         22283                        35123   \n",
       "3                          4699                        35123   \n",
       "4                          7170                          152   \n",
       "...                         ...                          ...   \n",
       "9764                      22283                        35123   \n",
       "9765                      22283                        35123   \n",
       "9766                       7170                        35123   \n",
       "9767                       7170                        35123   \n",
       "9768                      22283                        35123   \n",
       "\n",
       "      fnlwgt_/_education-num  fnlwgt_*_education-num  fnlwgt_-_education-num  \\\n",
       "0               47002.666667               3807216.0                423015.0   \n",
       "1               22369.125000               1431624.0                178945.0   \n",
       "2               38776.222222               3140874.0                348977.0   \n",
       "3               21821.500000               2182150.0                218205.0   \n",
       "4               27113.888889               2196225.0                244016.0   \n",
       "...                      ...                     ...                     ...   \n",
       "9764             8472.428571               1660596.0                118600.0   \n",
       "9765            22870.888889               1852542.0                205829.0   \n",
       "9766            19430.400000               1943040.0                194294.0   \n",
       "9767            24572.400000               2457240.0                245714.0   \n",
       "9768            20306.333333               1644813.0                182748.0   \n",
       "\n",
       "      fnlwgt_+_education-num  \n",
       "0                   423033.0  \n",
       "1                   178961.0  \n",
       "2                   348995.0  \n",
       "3                   218225.0  \n",
       "4                   244034.0  \n",
       "...                      ...  \n",
       "9764                118628.0  \n",
       "9765                205847.0  \n",
       "9766                194314.0  \n",
       "9767                245734.0  \n",
       "9768                182766.0  \n",
       "\n",
       "[9769 rows x 153 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>...</th>\n      <th>CountEncoder_relationship</th>\n      <th>CountEncoder_race</th>\n      <th>CountEncoder_capitalgain</th>\n      <th>CountEncoder_capitalloss</th>\n      <th>CountEncoder_hoursperweek</th>\n      <th>CountEncoder_native-country</th>\n      <th>fnlwgt_/_education-num</th>\n      <th>fnlwgt_*_education-num</th>\n      <th>fnlwgt_-_education-num</th>\n      <th>fnlwgt_+_education-num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>1</td>\n      <td>423024.0</td>\n      <td>1</td>\n      <td>9.0</td>\n      <td>4</td>\n      <td>6</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>10067</td>\n      <td>33425</td>\n      <td>35788</td>\n      <td>37253</td>\n      <td>3582</td>\n      <td>35123</td>\n      <td>47002.666667</td>\n      <td>3807216.0</td>\n      <td>423015.0</td>\n      <td>423033.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>1</td>\n      <td>178953.0</td>\n      <td>3</td>\n      <td>8.0</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>6122</td>\n      <td>33425</td>\n      <td>35788</td>\n      <td>37253</td>\n      <td>3582</td>\n      <td>35123</td>\n      <td>22369.125000</td>\n      <td>1431624.0</td>\n      <td>178945.0</td>\n      <td>178961.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>3</td>\n      <td>348986.0</td>\n      <td>1</td>\n      <td>9.0</td>\n      <td>4</td>\n      <td>10</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1180</td>\n      <td>3734</td>\n      <td>35788</td>\n      <td>37253</td>\n      <td>22283</td>\n      <td>35123</td>\n      <td>38776.222222</td>\n      <td>3140874.0</td>\n      <td>348977.0</td>\n      <td>348995.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>1</td>\n      <td>218215.0</td>\n      <td>6</td>\n      <td>10.0</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>6122</td>\n      <td>33425</td>\n      <td>35788</td>\n      <td>37253</td>\n      <td>4699</td>\n      <td>35123</td>\n      <td>21821.500000</td>\n      <td>2182150.0</td>\n      <td>218205.0</td>\n      <td>218225.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>244025.0</td>\n      <td>1</td>\n      <td>9.0</td>\n      <td>4</td>\n      <td>11</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4059</td>\n      <td>374</td>\n      <td>35788</td>\n      <td>37253</td>\n      <td>7170</td>\n      <td>152</td>\n      <td>27113.888889</td>\n      <td>2196225.0</td>\n      <td>244016.0</td>\n      <td>244034.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9764</th>\n      <td>3</td>\n      <td>4</td>\n      <td>118614.0</td>\n      <td>2</td>\n      <td>14.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4059</td>\n      <td>33425</td>\n      <td>35788</td>\n      <td>37253</td>\n      <td>22283</td>\n      <td>35123</td>\n      <td>8472.428571</td>\n      <td>1660596.0</td>\n      <td>118600.0</td>\n      <td>118628.0</td>\n    </tr>\n    <tr>\n      <th>9765</th>\n      <td>5</td>\n      <td>1</td>\n      <td>205838.0</td>\n      <td>1</td>\n      <td>9.0</td>\n      <td>4</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>6122</td>\n      <td>33425</td>\n      <td>35788</td>\n      <td>37253</td>\n      <td>22283</td>\n      <td>35123</td>\n      <td>22870.888889</td>\n      <td>1852542.0</td>\n      <td>205829.0</td>\n      <td>205847.0</td>\n    </tr>\n    <tr>\n      <th>9766</th>\n      <td>2</td>\n      <td>1</td>\n      <td>194304.0</td>\n      <td>6</td>\n      <td>10.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>10067</td>\n      <td>3734</td>\n      <td>35788</td>\n      <td>37253</td>\n      <td>7170</td>\n      <td>35123</td>\n      <td>19430.400000</td>\n      <td>1943040.0</td>\n      <td>194294.0</td>\n      <td>194314.0</td>\n    </tr>\n    <tr>\n      <th>9767</th>\n      <td>4</td>\n      <td>4</td>\n      <td>245724.0</td>\n      <td>6</td>\n      <td>10.0</td>\n      <td>2</td>\n      <td>8</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>10067</td>\n      <td>33425</td>\n      <td>35788</td>\n      <td>37253</td>\n      <td>7170</td>\n      <td>35123</td>\n      <td>24572.400000</td>\n      <td>2457240.0</td>\n      <td>245714.0</td>\n      <td>245734.0</td>\n    </tr>\n    <tr>\n      <th>9768</th>\n      <td>2</td>\n      <td>1</td>\n      <td>182757.0</td>\n      <td>1</td>\n      <td>9.0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>15748</td>\n      <td>33425</td>\n      <td>35788</td>\n      <td>37253</td>\n      <td>22283</td>\n      <td>35123</td>\n      <td>20306.333333</td>\n      <td>1644813.0</td>\n      <td>182748.0</td>\n      <td>182766.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>9769 rows × 153 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "de.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:23:55.231008Z",
     "start_time": "2020-05-07T04:23:55.209899Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 39073 entries, 0 to 39072\nColumns: 149 entries, age to CountEncoder_native-country\ndtypes: category(1), float64(126), int64(22)\nmemory usage: 44.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the data is quite dirty, there are object/category features and nans. But the **model is successfully trained even in such a dirty dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:38:37.740374Z",
     "start_time": "2020-05-07T01:38:37.732963Z"
    }
   },
   "source": [
    "[RUS] Как мы видим, данные довольно грязные, есть object/category признаки и nans. Но модель успешно обучаеться даже таком грязном датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:23:58.470851Z",
     "start_time": "2020-05-07T04:23:56.885982Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LightGBMClassifier(X_train, y_train, X_test, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:24:10.501288Z",
     "start_time": "2020-05-07T04:23:58.473630Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1/1 [02:13<00:00, 133.73s/it]\n",
      " Mean Score roc_auc_score on 20 Folds: 0.9142 std: 0.00485\n",
      "Test AUC:  0.9119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit with default model parameters\n",
    "predicts = model.predict()\n",
    "print('Test AUC: ', round(sklearn.metrics.roc_auc_score(y_test, predicts['predict_test'][0]),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How is this possible?**      \n",
    "[RUS] как это возможно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T01:51:30.503806Z",
     "start_time": "2020-05-07T01:51:30.489339Z"
    }
   },
   "source": [
    "<img src=\"./img/magic.gif\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataBunch\n",
    "before entering the model, the data goes through a full cycle of pre-processing in DataBunch     \n",
    "[RUS] до того как попасть в модель, данные проходят полный цикл предобработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:24:11.924652Z",
     "start_time": "2020-05-07T04:24:10.506103Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Source X_train shape:  (39073, 14) | X_test shape:  (9769, 14)\n",
      "##################################################\n",
      "Auto detect cat features:  12\n",
      "> Start preprocessing Data\n",
      "> Generate cat encodet features\n",
      " +  121  Features from  OneHotEncoder\n",
      "> Clean Nans in num features\n",
      "##################################################\n",
      "> Total Features:  122\n",
      "##################################################\n",
      "New X_train shape:  (39073, 122) | X_test shape:  (9769, 122)\n"
     ]
    }
   ],
   "source": [
    "data = DataBunch(X_train=X_train, \n",
    "                y_train=y_train,\n",
    "                X_test=X_test, # be sure to specify X_test, because the encoder needs all dataset to work.\n",
    "                clean_and_encod_data=True,\n",
    "                cat_encoder_names=['OneHotEncoder',], # Encoders list for Generator cat encodet features\n",
    "                clean_nan=True, # fillnan\n",
    "                num_generator_features=False, # Generator interaction Num Features\n",
    "                group_generator_features=False, # Generator Group Encoder Features\n",
    "                frequency_enc_num_features=False,\n",
    "                normalization=False,\n",
    "                cat_features=None, # DataBunch can auto detect categorical features\n",
    "                random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:24:11.943189Z",
     "start_time": "2020-05-07T04:24:11.927186Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     fnlwgt  OneHotEncoder_relationship_1  OneHotEncoder_relationship_2  \\\n",
       "0   50753.0                             1                             0   \n",
       "1  144351.0                             1                             0   \n",
       "2  252217.0                             1                             0   \n",
       "3   69525.0                             0                             1   \n",
       "4   28612.0                             0                             0   \n",
       "\n",
       "   OneHotEncoder_relationship_3  OneHotEncoder_relationship_4  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             1                             0   \n",
       "\n",
       "   OneHotEncoder_relationship_5  OneHotEncoder_relationship_6  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "\n",
       "   OneHotEncoder_race_1  OneHotEncoder_race_2  OneHotEncoder_race_3  ...  \\\n",
       "0                     1                     0                     0  ...   \n",
       "1                     1                     0                     0  ...   \n",
       "2                     1                     0                     0  ...   \n",
       "3                     1                     0                     0  ...   \n",
       "4                     1                     0                     0  ...   \n",
       "\n",
       "   OneHotEncoder_education_14  OneHotEncoder_education_15  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   OneHotEncoder_education_16  OneHotEncoder_marital-status_1  \\\n",
       "0                           0                               1   \n",
       "1                           0                               1   \n",
       "2                           0                               1   \n",
       "3                           0                               0   \n",
       "4                           0                               0   \n",
       "\n",
       "   OneHotEncoder_marital-status_2  OneHotEncoder_marital-status_3  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "2                               0                               0   \n",
       "3                               1                               0   \n",
       "4                               0                               1   \n",
       "\n",
       "   OneHotEncoder_marital-status_4  OneHotEncoder_marital-status_5  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "2                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "\n",
       "   OneHotEncoder_marital-status_6  OneHotEncoder_marital-status_7  \n",
       "0                               0                               0  \n",
       "1                               0                               0  \n",
       "2                               0                               0  \n",
       "3                               0                               0  \n",
       "4                               0                               0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fnlwgt</th>\n      <th>OneHotEncoder_relationship_1</th>\n      <th>OneHotEncoder_relationship_2</th>\n      <th>OneHotEncoder_relationship_3</th>\n      <th>OneHotEncoder_relationship_4</th>\n      <th>OneHotEncoder_relationship_5</th>\n      <th>OneHotEncoder_relationship_6</th>\n      <th>OneHotEncoder_race_1</th>\n      <th>OneHotEncoder_race_2</th>\n      <th>OneHotEncoder_race_3</th>\n      <th>...</th>\n      <th>OneHotEncoder_education_14</th>\n      <th>OneHotEncoder_education_15</th>\n      <th>OneHotEncoder_education_16</th>\n      <th>OneHotEncoder_marital-status_1</th>\n      <th>OneHotEncoder_marital-status_2</th>\n      <th>OneHotEncoder_marital-status_3</th>\n      <th>OneHotEncoder_marital-status_4</th>\n      <th>OneHotEncoder_marital-status_5</th>\n      <th>OneHotEncoder_marital-status_6</th>\n      <th>OneHotEncoder_marital-status_7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50753.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>144351.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>252217.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>69525.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28612.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 122 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "data.X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Features \n",
    "### Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:24:11.951750Z",
     "start_time": "2020-05-07T04:24:11.945886Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'HashingEncoder': category_encoders.hashing.HashingEncoder,\n",
       " 'SumEncoder': category_encoders.sum_coding.SumEncoder,\n",
       " 'PolynomialEncoder': category_encoders.polynomial.PolynomialEncoder,\n",
       " 'BackwardDifferenceEncoder': category_encoders.backward_difference.BackwardDifferenceEncoder,\n",
       " 'OneHotEncoder': category_encoders.one_hot.OneHotEncoder,\n",
       " 'HelmertEncoder': category_encoders.helmert.HelmertEncoder,\n",
       " 'OrdinalEncoder': category_encoders.ordinal.OrdinalEncoder,\n",
       " 'FrequencyEncoder': automl_alex.encoders.FrequencyEncoder,\n",
       " 'BaseNEncoder': category_encoders.basen.BaseNEncoder}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# available Encoders:\n",
    "automl_alex.encoders.cat_encoders_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:24:13.268269Z",
     "start_time": "2020-05-07T04:24:11.964195Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Source X_train shape:  (39073, 14) | X_test shape:  (9769, 14)\n",
      "##################################################\n",
      "Auto detect cat features:  12\n",
      "> Start preprocessing Data\n",
      "> Generate cat encodet features\n",
      " +  13  Features from  OrdinalEncoder\n",
      " +  13  Features from  FrequencyEncoder\n",
      "> Clean Nans in num features\n",
      "##################################################\n",
      "> Total Features:  27\n",
      "##################################################\n",
      "New X_train shape:  (39073, 27) | X_test shape:  (9769, 27)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     fnlwgt  OrdinalEncoder_relationship  OrdinalEncoder_race  \\\n",
       "0   50753.0                            1                    1   \n",
       "1  144351.0                            1                    1   \n",
       "2  252217.0                            1                    1   \n",
       "3   69525.0                            2                    1   \n",
       "4   28612.0                            3                    1   \n",
       "\n",
       "   OrdinalEncoder_hoursperweek  OrdinalEncoder_workclass  \\\n",
       "0                            1                         1   \n",
       "1                            1                         2   \n",
       "2                            1                         3   \n",
       "3                            2                         1   \n",
       "4                            3                         4   \n",
       "\n",
       "   OrdinalEncoder_occupation  OrdinalEncoder_capitalloss  \\\n",
       "0                          1                           1   \n",
       "1                          2                           1   \n",
       "2                          3                           1   \n",
       "3                          4                           1   \n",
       "4                          5                           1   \n",
       "\n",
       "   OrdinalEncoder_native-country  OrdinalEncoder_sex  OrdinalEncoder_age  ...  \\\n",
       "0                              1                   1                   1  ...   \n",
       "1                              1                   1                   2  ...   \n",
       "2                              1                   1                   1  ...   \n",
       "3                              1                   1                   3  ...   \n",
       "4                              1                   1                   3  ...   \n",
       "\n",
       "   FrequencyEncoder_workclass  FrequencyEncoder_occupation  \\\n",
       "0                    0.694198                     0.048217   \n",
       "1                    0.040559                     0.126367   \n",
       "2                    0.064207                     0.030507   \n",
       "3                    0.694198                     0.125138   \n",
       "4                    0.079071                     0.112690   \n",
       "\n",
       "   FrequencyEncoder_capitalloss  FrequencyEncoder_native-country  \\\n",
       "0                      0.953278                         0.897424   \n",
       "1                      0.953278                         0.897424   \n",
       "2                      0.953278                         0.897424   \n",
       "3                      0.953278                         0.897424   \n",
       "4                      0.953278                         0.897424   \n",
       "\n",
       "   FrequencyEncoder_sex  FrequencyEncoder_age  FrequencyEncoder_education-num  \\\n",
       "0              0.668482              0.260411                        0.323164   \n",
       "1              0.668482              0.244707                        0.054400   \n",
       "2              0.668482              0.260411                        0.013452   \n",
       "3              0.668482              0.127923                        0.323164   \n",
       "4              0.668482              0.127923                        0.323164   \n",
       "\n",
       "   FrequencyEncoder_capitalgain  FrequencyEncoder_education  \\\n",
       "0                      0.917387                    0.323164   \n",
       "1                      0.917387                    0.054400   \n",
       "2                      0.917387                    0.013452   \n",
       "3                      0.917387                    0.323164   \n",
       "4                      0.917387                    0.323164   \n",
       "\n",
       "   FrequencyEncoder_marital-status  \n",
       "0                         0.458192  \n",
       "1                         0.458192  \n",
       "2                         0.458192  \n",
       "3                         0.135805  \n",
       "4                         0.031080  \n",
       "\n",
       "[5 rows x 27 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fnlwgt</th>\n      <th>OrdinalEncoder_relationship</th>\n      <th>OrdinalEncoder_race</th>\n      <th>OrdinalEncoder_hoursperweek</th>\n      <th>OrdinalEncoder_workclass</th>\n      <th>OrdinalEncoder_occupation</th>\n      <th>OrdinalEncoder_capitalloss</th>\n      <th>OrdinalEncoder_native-country</th>\n      <th>OrdinalEncoder_sex</th>\n      <th>OrdinalEncoder_age</th>\n      <th>...</th>\n      <th>FrequencyEncoder_workclass</th>\n      <th>FrequencyEncoder_occupation</th>\n      <th>FrequencyEncoder_capitalloss</th>\n      <th>FrequencyEncoder_native-country</th>\n      <th>FrequencyEncoder_sex</th>\n      <th>FrequencyEncoder_age</th>\n      <th>FrequencyEncoder_education-num</th>\n      <th>FrequencyEncoder_capitalgain</th>\n      <th>FrequencyEncoder_education</th>\n      <th>FrequencyEncoder_marital-status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50753.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.694198</td>\n      <td>0.048217</td>\n      <td>0.953278</td>\n      <td>0.897424</td>\n      <td>0.668482</td>\n      <td>0.260411</td>\n      <td>0.323164</td>\n      <td>0.917387</td>\n      <td>0.323164</td>\n      <td>0.458192</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>144351.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.040559</td>\n      <td>0.126367</td>\n      <td>0.953278</td>\n      <td>0.897424</td>\n      <td>0.668482</td>\n      <td>0.244707</td>\n      <td>0.054400</td>\n      <td>0.917387</td>\n      <td>0.054400</td>\n      <td>0.458192</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>252217.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.064207</td>\n      <td>0.030507</td>\n      <td>0.953278</td>\n      <td>0.897424</td>\n      <td>0.668482</td>\n      <td>0.260411</td>\n      <td>0.013452</td>\n      <td>0.917387</td>\n      <td>0.013452</td>\n      <td>0.458192</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>69525.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.694198</td>\n      <td>0.125138</td>\n      <td>0.953278</td>\n      <td>0.897424</td>\n      <td>0.668482</td>\n      <td>0.127923</td>\n      <td>0.323164</td>\n      <td>0.917387</td>\n      <td>0.323164</td>\n      <td>0.135805</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28612.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.079071</td>\n      <td>0.112690</td>\n      <td>0.953278</td>\n      <td>0.897424</td>\n      <td>0.668482</td>\n      <td>0.127923</td>\n      <td>0.323164</td>\n      <td>0.917387</td>\n      <td>0.323164</td>\n      <td>0.031080</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "data = DataBunch(X_train=X_train, \n",
    "                y_train=y_train,\n",
    "                X_test=X_test, # be sure to specify X_test, because the encoder needs all dataset to work.\n",
    "                clean_and_encod_data=True,\n",
    "                cat_encoder_names=['OrdinalEncoder', 'FrequencyEncoder',], # you can choose any encoders\n",
    "                clean_nan=True, # fillnan\n",
    "                #cat_features=categorical_features, # DataBunch can detect categorical features itself.\n",
    "                num_generator_features=False, # Generator interaction Num Features\n",
    "                group_generator_features=False, # Generator Group Encoder Features\n",
    "                frequency_enc_num_features=False,\n",
    "                normalization=False,\n",
    "                random_state=RANDOM_SEED)\n",
    "data.X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding cat features by Groupby with numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dataset whis more num features\n",
    "dataset = fetch_openml(name='credit-g', version=1, as_frame=True)\n",
    "dataset.target = dataset.target.astype('category').cat.codes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.2, random_state=RANDOM_SEED,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Source X_train shape:  (800, 20) | X_test shape:  (200, 20)\n##################################################\nAuto detect cat features:  13\n> Start preprocessing Data\n> Clean Nans in num features\n> Generate Group Encoder Features\n +  64  Group cat Encoder Features\n##################################################\n> Total Features:  68\n##################################################\nNew X_train shape:  (800, 68) | X_test shape:  (200, 68)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   duration  credit_amount   age  num_dependents  \\\n",
       "0      60.0         6836.0  63.0               0   \n",
       "1      21.0         2319.0  33.0               0   \n",
       "2       6.0         1236.0  50.0               0   \n",
       "3      21.0         5003.0  29.0               0   \n",
       "4      12.0          886.0  21.0               0   \n",
       "\n",
       "   GroupEncoder_age_installment_commitment  GroupEncoder_age_residence_since  \\\n",
       "0                                        2                                 3   \n",
       "1                                        1                                 0   \n",
       "2                                        1                                 3   \n",
       "3                                        0                                 3   \n",
       "4                                        3                                 1   \n",
       "\n",
       "   GroupEncoder_age_other_payment_plans  GroupEncoder_age_existing_credits  \\\n",
       "0                                     2                                  1   \n",
       "1                                     2                                  0   \n",
       "2                                     2                                  0   \n",
       "3                                     0                                  1   \n",
       "4                                     2                                  0   \n",
       "\n",
       "   GroupEncoder_age_foreign_worker  GroupEncoder_age_housing  ...  \\\n",
       "0                                0                         1  ...   \n",
       "1                                0                         0  ...   \n",
       "2                                0                         0  ...   \n",
       "3                                0                         1  ...   \n",
       "4                                0                         1  ...   \n",
       "\n",
       "   GroupEncoder_num_dependents_savings_status  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           2   \n",
       "3                                           4   \n",
       "4                                           4   \n",
       "\n",
       "   GroupEncoder_num_dependents_credit_history  \\\n",
       "0                                           3   \n",
       "1                                           4   \n",
       "2                                           2   \n",
       "3                                           0   \n",
       "4                                           2   \n",
       "\n",
       "   GroupEncoder_num_dependents_job  \\\n",
       "0                                2   \n",
       "1                                2   \n",
       "2                                2   \n",
       "3                                2   \n",
       "4                                2   \n",
       "\n",
       "   GroupEncoder_num_dependents_property_magnitude  \\\n",
       "0                                               3   \n",
       "1                                               2   \n",
       "2                                               1   \n",
       "3                                               1   \n",
       "4                                               2   \n",
       "\n",
       "   GroupEncoder_num_dependents_employment  \\\n",
       "0                                       4   \n",
       "1                                       1   \n",
       "2                                       2   \n",
       "3                                       2   \n",
       "4                                       2   \n",
       "\n",
       "   GroupEncoder_num_dependents_checking_status  \\\n",
       "0                                            0   \n",
       "1                                            2   \n",
       "2                                            3   \n",
       "3                                            3   \n",
       "4                                            3   \n",
       "\n",
       "   GroupEncoder_num_dependents_purpose  \\\n",
       "0                                    9   \n",
       "1                                    6   \n",
       "2                                    1   \n",
       "3                                    0   \n",
       "4                                    3   \n",
       "\n",
       "   GroupEncoder_num_dependents_other_parties  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "\n",
       "   GroupEncoder_num_dependents_personal_status  \\\n",
       "0                                            2   \n",
       "1                                            0   \n",
       "2                                            2   \n",
       "3                                            1   \n",
       "4                                            1   \n",
       "\n",
       "   GroupEncoder_num_dependents_own_telephone  \n",
       "0                                          1  \n",
       "1                                          0  \n",
       "2                                          0  \n",
       "3                                          1  \n",
       "4                                          0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>credit_amount</th>\n      <th>age</th>\n      <th>num_dependents</th>\n      <th>GroupEncoder_age_installment_commitment</th>\n      <th>GroupEncoder_age_residence_since</th>\n      <th>GroupEncoder_age_other_payment_plans</th>\n      <th>GroupEncoder_age_existing_credits</th>\n      <th>GroupEncoder_age_foreign_worker</th>\n      <th>GroupEncoder_age_housing</th>\n      <th>...</th>\n      <th>GroupEncoder_num_dependents_savings_status</th>\n      <th>GroupEncoder_num_dependents_credit_history</th>\n      <th>GroupEncoder_num_dependents_job</th>\n      <th>GroupEncoder_num_dependents_property_magnitude</th>\n      <th>GroupEncoder_num_dependents_employment</th>\n      <th>GroupEncoder_num_dependents_checking_status</th>\n      <th>GroupEncoder_num_dependents_purpose</th>\n      <th>GroupEncoder_num_dependents_other_parties</th>\n      <th>GroupEncoder_num_dependents_personal_status</th>\n      <th>GroupEncoder_num_dependents_own_telephone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60.0</td>\n      <td>6836.0</td>\n      <td>63.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21.0</td>\n      <td>2319.0</td>\n      <td>33.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.0</td>\n      <td>1236.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21.0</td>\n      <td>5003.0</td>\n      <td>29.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12.0</td>\n      <td>886.0</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 68 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "data = DataBunch(X_train=X_train, \n",
    "                y_train=y_train,\n",
    "                X_test=X_test, # be sure to specify X_test, because the encoder needs all dataset to work.\n",
    "                clean_and_encod_data=True,\n",
    "                cat_encoder_names=None, # False if None\n",
    "                clean_nan=True, # fillnan\n",
    "                #cat_features=categorical_features, # DataBunch can detect categorical features itself.\n",
    "                num_generator_features=False, # Generator interaction Num Features\n",
    "                group_generator_features=True, # Generator Group Encoder Features\n",
    "                frequency_enc_num_features=False,\n",
    "                normalization=False,\n",
    "                random_state=RANDOM_SEED)\n",
    "data.X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['age', 'credit_amount', 'duration', 'num_dependents']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "data.num_features_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator interaction Num Features\n",
    "Numerical interaction generator features: A/B, A*B, A-B, A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Source X_train shape:  (800, 20) | X_test shape:  (200, 20)\n",
      "##################################################\n",
      "Auto detect cat features:  13\n",
      "> Start preprocessing Data\n",
      "> Clean Nans in num features\n",
      "> Generate interaction Num Features\n",
      " +  24  Interaction Features\n",
      "##################################################\n",
      "> Total Features:  28\n",
      "##################################################\n",
      "New X_train shape:  (800, 28) | X_test shape:  (200, 28)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   duration  credit_amount   age  num_dependents  age_/_credit_amount  \\\n",
       "0      60.0         6836.0  63.0               0             0.009216   \n",
       "1      21.0         2319.0  33.0               0             0.014230   \n",
       "2       6.0         1236.0  50.0               0             0.040453   \n",
       "3      21.0         5003.0  29.0               0             0.005797   \n",
       "4      12.0          886.0  21.0               0             0.023702   \n",
       "\n",
       "   age_*_credit_amount  age_-_credit_amount  age_+_credit_amount  \\\n",
       "0             430668.0              -6773.0               6899.0   \n",
       "1              76527.0              -2286.0               2352.0   \n",
       "2              61800.0              -1186.0               1286.0   \n",
       "3             145087.0              -4974.0               5032.0   \n",
       "4              18606.0               -865.0                907.0   \n",
       "\n",
       "   age_/_duration  age_*_duration  ...  credit_amount_-_duration  \\\n",
       "0        1.050000          3780.0  ...                    6776.0   \n",
       "1        1.571429           693.0  ...                    2298.0   \n",
       "2        8.333333           300.0  ...                    1230.0   \n",
       "3        1.380952           609.0  ...                    4982.0   \n",
       "4        1.750000           252.0  ...                     874.0   \n",
       "\n",
       "   credit_amount_+_duration  credit_amount_/_num_dependents  \\\n",
       "0                    6896.0                             0.0   \n",
       "1                    2340.0                             0.0   \n",
       "2                    1242.0                             0.0   \n",
       "3                    5024.0                             0.0   \n",
       "4                     898.0                             0.0   \n",
       "\n",
       "   credit_amount_*_num_dependents  credit_amount_-_num_dependents  \\\n",
       "0                             0.0                          6836.0   \n",
       "1                             0.0                          2319.0   \n",
       "2                             0.0                          1236.0   \n",
       "3                             0.0                          5003.0   \n",
       "4                             0.0                           886.0   \n",
       "\n",
       "   credit_amount_+_num_dependents  duration_/_num_dependents  \\\n",
       "0                          6836.0                        0.0   \n",
       "1                          2319.0                        0.0   \n",
       "2                          1236.0                        0.0   \n",
       "3                          5003.0                        0.0   \n",
       "4                           886.0                        0.0   \n",
       "\n",
       "   duration_*_num_dependents  duration_-_num_dependents  \\\n",
       "0                        0.0                       60.0   \n",
       "1                        0.0                       21.0   \n",
       "2                        0.0                        6.0   \n",
       "3                        0.0                       21.0   \n",
       "4                        0.0                       12.0   \n",
       "\n",
       "   duration_+_num_dependents  \n",
       "0                       60.0  \n",
       "1                       21.0  \n",
       "2                        6.0  \n",
       "3                       21.0  \n",
       "4                       12.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>credit_amount</th>\n      <th>age</th>\n      <th>num_dependents</th>\n      <th>age_/_credit_amount</th>\n      <th>age_*_credit_amount</th>\n      <th>age_-_credit_amount</th>\n      <th>age_+_credit_amount</th>\n      <th>age_/_duration</th>\n      <th>age_*_duration</th>\n      <th>...</th>\n      <th>credit_amount_-_duration</th>\n      <th>credit_amount_+_duration</th>\n      <th>credit_amount_/_num_dependents</th>\n      <th>credit_amount_*_num_dependents</th>\n      <th>credit_amount_-_num_dependents</th>\n      <th>credit_amount_+_num_dependents</th>\n      <th>duration_/_num_dependents</th>\n      <th>duration_*_num_dependents</th>\n      <th>duration_-_num_dependents</th>\n      <th>duration_+_num_dependents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60.0</td>\n      <td>6836.0</td>\n      <td>63.0</td>\n      <td>0</td>\n      <td>0.009216</td>\n      <td>430668.0</td>\n      <td>-6773.0</td>\n      <td>6899.0</td>\n      <td>1.050000</td>\n      <td>3780.0</td>\n      <td>...</td>\n      <td>6776.0</td>\n      <td>6896.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6836.0</td>\n      <td>6836.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>60.0</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21.0</td>\n      <td>2319.0</td>\n      <td>33.0</td>\n      <td>0</td>\n      <td>0.014230</td>\n      <td>76527.0</td>\n      <td>-2286.0</td>\n      <td>2352.0</td>\n      <td>1.571429</td>\n      <td>693.0</td>\n      <td>...</td>\n      <td>2298.0</td>\n      <td>2340.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2319.0</td>\n      <td>2319.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.0</td>\n      <td>1236.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0.040453</td>\n      <td>61800.0</td>\n      <td>-1186.0</td>\n      <td>1286.0</td>\n      <td>8.333333</td>\n      <td>300.0</td>\n      <td>...</td>\n      <td>1230.0</td>\n      <td>1242.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1236.0</td>\n      <td>1236.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21.0</td>\n      <td>5003.0</td>\n      <td>29.0</td>\n      <td>0</td>\n      <td>0.005797</td>\n      <td>145087.0</td>\n      <td>-4974.0</td>\n      <td>5032.0</td>\n      <td>1.380952</td>\n      <td>609.0</td>\n      <td>...</td>\n      <td>4982.0</td>\n      <td>5024.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5003.0</td>\n      <td>5003.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12.0</td>\n      <td>886.0</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>0.023702</td>\n      <td>18606.0</td>\n      <td>-865.0</td>\n      <td>907.0</td>\n      <td>1.750000</td>\n      <td>252.0</td>\n      <td>...</td>\n      <td>874.0</td>\n      <td>898.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>886.0</td>\n      <td>886.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>12.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "data = DataBunch(X_train=X_train, \n",
    "                y_train=y_train,\n",
    "                X_test=X_test, # be sure to specify X_test, because the encoder needs all dataset to work.\n",
    "                clean_and_encod_data=True,\n",
    "                cat_encoder_names=None, # False if None\n",
    "                clean_nan=True, # fillnan\n",
    "                #cat_features=categorical_features, # DataBunch can detect categorical features itself.\n",
    "                num_generator_features=True, # Generator interaction Num Features\n",
    "                group_generator_features=False, # Generator Group Encoder Features\n",
    "                frequency_enc_num_features=False,\n",
    "                normalization=False,\n",
    "                random_state=RANDOM_SEED)\n",
    "data.X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Encoder Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Source X_train shape:  (800, 20) | X_test shape:  (200, 20)\n",
      "##################################################\n",
      "Auto detect cat features:  13\n",
      "> Start preprocessing Data\n",
      "> Generate Frequency Encode num features\n",
      " +  4  Frequency Encode Num Features \n",
      "> Clean Nans in num features\n",
      "##################################################\n",
      "> Total Features:  8\n",
      "##################################################\n",
      "New X_train shape:  (800, 8) | X_test shape:  (200, 8)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   duration  credit_amount   age  num_dependents  FrequencyEncoder_age  \\\n",
       "0      60.0         6836.0  63.0               0                 0.008   \n",
       "1      21.0         2319.0  33.0               0                 0.033   \n",
       "2       6.0         1236.0  50.0               0                 0.012   \n",
       "3      21.0         5003.0  29.0               0                 0.037   \n",
       "4      12.0          886.0  21.0               0                 0.014   \n",
       "\n",
       "   FrequencyEncoder_credit_amount  FrequencyEncoder_duration  \\\n",
       "0                           0.001                      0.013   \n",
       "1                           0.001                      0.030   \n",
       "2                           0.002                      0.075   \n",
       "3                           0.001                      0.030   \n",
       "4                           0.001                      0.179   \n",
       "\n",
       "   FrequencyEncoder_num_dependents  \n",
       "0                            0.845  \n",
       "1                            0.845  \n",
       "2                            0.845  \n",
       "3                            0.845  \n",
       "4                            0.845  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>credit_amount</th>\n      <th>age</th>\n      <th>num_dependents</th>\n      <th>FrequencyEncoder_age</th>\n      <th>FrequencyEncoder_credit_amount</th>\n      <th>FrequencyEncoder_duration</th>\n      <th>FrequencyEncoder_num_dependents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60.0</td>\n      <td>6836.0</td>\n      <td>63.0</td>\n      <td>0</td>\n      <td>0.008</td>\n      <td>0.001</td>\n      <td>0.013</td>\n      <td>0.845</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21.0</td>\n      <td>2319.0</td>\n      <td>33.0</td>\n      <td>0</td>\n      <td>0.033</td>\n      <td>0.001</td>\n      <td>0.030</td>\n      <td>0.845</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.0</td>\n      <td>1236.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0.012</td>\n      <td>0.002</td>\n      <td>0.075</td>\n      <td>0.845</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21.0</td>\n      <td>5003.0</td>\n      <td>29.0</td>\n      <td>0</td>\n      <td>0.037</td>\n      <td>0.001</td>\n      <td>0.030</td>\n      <td>0.845</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12.0</td>\n      <td>886.0</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>0.014</td>\n      <td>0.001</td>\n      <td>0.179</td>\n      <td>0.845</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "data = DataBunch(X_train=X_train, \n",
    "                y_train=y_train,\n",
    "                X_test=X_test, # be sure to specify X_test, because the encoder needs all dataset to work.\n",
    "                clean_and_encod_data=True,\n",
    "                cat_encoder_names=None, # False if None\n",
    "                clean_nan=True, # fillnan\n",
    "                #cat_features=categorical_features, # DataBunch can detect categorical features itself.\n",
    "                num_generator_features=False, # Generator interaction Num Features\n",
    "                group_generator_features=False, # Generator Group Encoder Features\n",
    "                frequency_enc_num_features=True, \n",
    "                normalization=False,\n",
    "                random_state=RANDOM_SEED)\n",
    "data.X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization Data\n",
    "use StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Source X_train shape:  (800, 20) | X_test shape:  (200, 20)\n",
      "##################################################\n",
      "Auto detect cat features:  13\n",
      "> Start preprocessing Data\n",
      "> Generate Frequency Encode num features\n",
      " +  4  Frequency Encode Num Features \n",
      "> Clean Nans in num features\n",
      "> Normalization Features\n",
      "##################################################\n",
      "> Total Features:  8\n",
      "##################################################\n",
      "New X_train shape:  (800, 8) | X_test shape:  (200, 8)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   duration  credit_amount       age  num_dependents  FrequencyEncoder_age  \\\n",
       "0  3.297082       1.199912  2.406187       -0.409736             -1.603822   \n",
       "1 -0.008051      -0.359630 -0.224364       -0.409736              0.166108   \n",
       "2 -1.279256      -0.733547  1.266282       -0.409736             -1.320634   \n",
       "3 -0.008051       0.567050 -0.575104       -0.409736              0.449297   \n",
       "4 -0.770774      -0.854388 -1.276585       -0.409736             -1.179039   \n",
       "\n",
       "   FrequencyEncoder_credit_amount  FrequencyEncoder_duration  \\\n",
       "0                       -0.403815                  -1.406620   \n",
       "1                       -0.403815                  -1.142860   \n",
       "2                        2.062233                  -0.444670   \n",
       "3                       -0.403815                  -1.142860   \n",
       "4                       -0.403815                   1.168925   \n",
       "\n",
       "   FrequencyEncoder_num_dependents  \n",
       "0                         0.409736  \n",
       "1                         0.409736  \n",
       "2                         0.409736  \n",
       "3                         0.409736  \n",
       "4                         0.409736  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>credit_amount</th>\n      <th>age</th>\n      <th>num_dependents</th>\n      <th>FrequencyEncoder_age</th>\n      <th>FrequencyEncoder_credit_amount</th>\n      <th>FrequencyEncoder_duration</th>\n      <th>FrequencyEncoder_num_dependents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.297082</td>\n      <td>1.199912</td>\n      <td>2.406187</td>\n      <td>-0.409736</td>\n      <td>-1.603822</td>\n      <td>-0.403815</td>\n      <td>-1.406620</td>\n      <td>0.409736</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.008051</td>\n      <td>-0.359630</td>\n      <td>-0.224364</td>\n      <td>-0.409736</td>\n      <td>0.166108</td>\n      <td>-0.403815</td>\n      <td>-1.142860</td>\n      <td>0.409736</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.279256</td>\n      <td>-0.733547</td>\n      <td>1.266282</td>\n      <td>-0.409736</td>\n      <td>-1.320634</td>\n      <td>2.062233</td>\n      <td>-0.444670</td>\n      <td>0.409736</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.008051</td>\n      <td>0.567050</td>\n      <td>-0.575104</td>\n      <td>-0.409736</td>\n      <td>0.449297</td>\n      <td>-0.403815</td>\n      <td>-1.142860</td>\n      <td>0.409736</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.770774</td>\n      <td>-0.854388</td>\n      <td>-1.276585</td>\n      <td>-0.409736</td>\n      <td>-1.179039</td>\n      <td>-0.403815</td>\n      <td>1.168925</td>\n      <td>0.409736</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "data = DataBunch(X_train=X_train, \n",
    "                y_train=y_train,\n",
    "                X_test=X_test, # be sure to specify X_test, because the encoder needs all dataset to work.\n",
    "                clean_and_encod_data=True,\n",
    "                cat_encoder_names=None, # False if None\n",
    "                clean_nan=True, # fillnan\n",
    "                #cat_features=categorical_features, # DataBunch can detect categorical features itself.\n",
    "                num_generator_features=False, # Generator interaction Num Features\n",
    "                group_generator_features=False, # Generator Group Encoder Features\n",
    "                frequency_enc_num_features=True, \n",
    "                normalization=True,\n",
    "                random_state=RANDOM_SEED)\n",
    "data.X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:02:06.925090Z",
     "start_time": "2020-05-07T04:02:06.922362Z"
    }
   },
   "source": [
    "# Model DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:24:13.307830Z",
     "start_time": "2020-05-07T04:24:13.271370Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   duration  credit_amount       age  num_dependents  FrequencyEncoder_age  \\\n",
       "0  3.297082       1.199912  2.406187       -0.409736             -1.603822   \n",
       "1 -0.008051      -0.359630 -0.224364       -0.409736              0.166108   \n",
       "2 -1.279256      -0.733547  1.266282       -0.409736             -1.320634   \n",
       "3 -0.008051       0.567050 -0.575104       -0.409736              0.449297   \n",
       "4 -0.770774      -0.854388 -1.276585       -0.409736             -1.179039   \n",
       "\n",
       "   FrequencyEncoder_credit_amount  FrequencyEncoder_duration  \\\n",
       "0                       -0.403815                  -1.406620   \n",
       "1                       -0.403815                  -1.142860   \n",
       "2                        2.062233                  -0.444670   \n",
       "3                       -0.403815                  -1.142860   \n",
       "4                       -0.403815                   1.168925   \n",
       "\n",
       "   FrequencyEncoder_num_dependents  \n",
       "0                         0.409736  \n",
       "1                         0.409736  \n",
       "2                         0.409736  \n",
       "3                         0.409736  \n",
       "4                         0.409736  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>credit_amount</th>\n      <th>age</th>\n      <th>num_dependents</th>\n      <th>FrequencyEncoder_age</th>\n      <th>FrequencyEncoder_credit_amount</th>\n      <th>FrequencyEncoder_duration</th>\n      <th>FrequencyEncoder_num_dependents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.297082</td>\n      <td>1.199912</td>\n      <td>2.406187</td>\n      <td>-0.409736</td>\n      <td>-1.603822</td>\n      <td>-0.403815</td>\n      <td>-1.406620</td>\n      <td>0.409736</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.008051</td>\n      <td>-0.359630</td>\n      <td>-0.224364</td>\n      <td>-0.409736</td>\n      <td>0.166108</td>\n      <td>-0.403815</td>\n      <td>-1.142860</td>\n      <td>0.409736</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.279256</td>\n      <td>-0.733547</td>\n      <td>1.266282</td>\n      <td>-0.409736</td>\n      <td>-1.320634</td>\n      <td>2.062233</td>\n      <td>-0.444670</td>\n      <td>0.409736</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.008051</td>\n      <td>0.567050</td>\n      <td>-0.575104</td>\n      <td>-0.409736</td>\n      <td>0.449297</td>\n      <td>-0.403815</td>\n      <td>-1.142860</td>\n      <td>0.409736</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.770774</td>\n      <td>-0.854388</td>\n      <td>-1.276585</td>\n      <td>-0.409736</td>\n      <td>-1.179039</td>\n      <td>-0.403815</td>\n      <td>1.168925</td>\n      <td>0.409736</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# After you can pass databunch in model\n",
    "model = LightGBMClassifier(databunch=data, random_state=RANDOM_SEED)\n",
    "model._data.X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:24:14.648430Z",
     "start_time": "2020-05-07T04:24:13.310331Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Source X_train shape:  (800, 20) | X_test shape:  (200, 20)\n",
      "##################################################\n",
      "Auto detect cat features:  13\n",
      "> Start preprocessing Data\n",
      "> Generate cat encodet features\n",
      " +  55  Features from  OneHotEncoder\n",
      " +  44  Features from  HelmertEncoder\n",
      " +  54  Features from  HashingEncoder\n",
      " +  16  Features from  FrequencyEncoder\n",
      "> Generate Frequency Encode num features\n",
      " +  4  Frequency Encode Num Features \n",
      "> Clean Nans in num features\n",
      "> Generate interaction Num Features\n",
      " +  24  Interaction Features\n",
      "> Normalization Features\n",
      "##################################################\n",
      "> Total Features:  201\n",
      "##################################################\n",
      "New X_train shape:  (800, 201) | X_test shape:  (200, 201)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   duration  credit_amount       age  num_dependents  \\\n",
       "0  3.297082       1.199912  2.406187       -0.409736   \n",
       "1 -0.008051      -0.359630 -0.224364       -0.409736   \n",
       "2 -1.279256      -0.733547  1.266282       -0.409736   \n",
       "3 -0.008051       0.567050 -0.575104       -0.409736   \n",
       "4 -0.770774      -0.854388 -1.276585       -0.409736   \n",
       "\n",
       "   OneHotEncoder_installment_commitment  OneHotEncoder_residence_since  \\\n",
       "0                              0.031196                       1.044509   \n",
       "1                             -0.860109                      -1.671440   \n",
       "2                             -0.860109                       1.044509   \n",
       "3                             -1.751413                       1.044509   \n",
       "4                              0.922500                      -0.766124   \n",
       "\n",
       "   OneHotEncoder_other_payment_plans_1  OneHotEncoder_other_payment_plans_2  \\\n",
       "0                             0.468521                            -0.397168   \n",
       "1                             0.468521                            -0.397168   \n",
       "2                             0.468521                            -0.397168   \n",
       "3                            -2.134375                             2.517826   \n",
       "4                             0.468521                            -0.397168   \n",
       "\n",
       "   OneHotEncoder_other_payment_plans_3  OneHotEncoder_existing_credits  ...  \\\n",
       "0                            -0.213896                        1.017777  ...   \n",
       "1                            -0.213896                       -0.710931  ...   \n",
       "2                            -0.213896                       -0.710931  ...   \n",
       "3                            -0.213896                        1.017777  ...   \n",
       "4                            -0.213896                       -0.710931  ...   \n",
       "\n",
       "   credit_amount_-_duration  credit_amount_+_duration  \\\n",
       "0                  1.189509                  1.210250   \n",
       "1                 -0.360515                 -0.358745   \n",
       "2                 -0.730195                 -0.736875   \n",
       "3                  0.568530                  0.565571   \n",
       "4                 -0.853422                 -0.855341   \n",
       "\n",
       "   credit_amount_/_num_dependents  credit_amount_*_num_dependents  \\\n",
       "0                       -0.320701                       -0.320701   \n",
       "1                       -0.320701                       -0.320701   \n",
       "2                       -0.320701                       -0.320701   \n",
       "3                       -0.320701                       -0.320701   \n",
       "4                       -0.320701                       -0.320701   \n",
       "\n",
       "   credit_amount_-_num_dependents  credit_amount_+_num_dependents  \\\n",
       "0                        1.199968                        1.199857   \n",
       "1                       -0.359582                       -0.359678   \n",
       "2                       -0.733501                       -0.733593   \n",
       "3                        0.567102                        0.566997   \n",
       "4                       -0.854343                       -0.854434   \n",
       "\n",
       "   duration_/_num_dependents  duration_*_num_dependents  \\\n",
       "0                  -0.344593                  -0.344593   \n",
       "1                  -0.344593                  -0.344593   \n",
       "2                  -0.344593                  -0.344593   \n",
       "3                  -0.344593                  -0.344593   \n",
       "4                  -0.344593                  -0.344593   \n",
       "\n",
       "   duration_-_num_dependents  duration_+_num_dependents  \n",
       "0                   3.307063                   3.284183  \n",
       "1                   0.004129                  -0.020229  \n",
       "2                  -1.266231                  -1.291156  \n",
       "3                   0.004129                  -0.020229  \n",
       "4                  -0.758087                  -0.782785  \n",
       "\n",
       "[5 rows x 201 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>credit_amount</th>\n      <th>age</th>\n      <th>num_dependents</th>\n      <th>OneHotEncoder_installment_commitment</th>\n      <th>OneHotEncoder_residence_since</th>\n      <th>OneHotEncoder_other_payment_plans_1</th>\n      <th>OneHotEncoder_other_payment_plans_2</th>\n      <th>OneHotEncoder_other_payment_plans_3</th>\n      <th>OneHotEncoder_existing_credits</th>\n      <th>...</th>\n      <th>credit_amount_-_duration</th>\n      <th>credit_amount_+_duration</th>\n      <th>credit_amount_/_num_dependents</th>\n      <th>credit_amount_*_num_dependents</th>\n      <th>credit_amount_-_num_dependents</th>\n      <th>credit_amount_+_num_dependents</th>\n      <th>duration_/_num_dependents</th>\n      <th>duration_*_num_dependents</th>\n      <th>duration_-_num_dependents</th>\n      <th>duration_+_num_dependents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.297082</td>\n      <td>1.199912</td>\n      <td>2.406187</td>\n      <td>-0.409736</td>\n      <td>0.031196</td>\n      <td>1.044509</td>\n      <td>0.468521</td>\n      <td>-0.397168</td>\n      <td>-0.213896</td>\n      <td>1.017777</td>\n      <td>...</td>\n      <td>1.189509</td>\n      <td>1.210250</td>\n      <td>-0.320701</td>\n      <td>-0.320701</td>\n      <td>1.199968</td>\n      <td>1.199857</td>\n      <td>-0.344593</td>\n      <td>-0.344593</td>\n      <td>3.307063</td>\n      <td>3.284183</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.008051</td>\n      <td>-0.359630</td>\n      <td>-0.224364</td>\n      <td>-0.409736</td>\n      <td>-0.860109</td>\n      <td>-1.671440</td>\n      <td>0.468521</td>\n      <td>-0.397168</td>\n      <td>-0.213896</td>\n      <td>-0.710931</td>\n      <td>...</td>\n      <td>-0.360515</td>\n      <td>-0.358745</td>\n      <td>-0.320701</td>\n      <td>-0.320701</td>\n      <td>-0.359582</td>\n      <td>-0.359678</td>\n      <td>-0.344593</td>\n      <td>-0.344593</td>\n      <td>0.004129</td>\n      <td>-0.020229</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.279256</td>\n      <td>-0.733547</td>\n      <td>1.266282</td>\n      <td>-0.409736</td>\n      <td>-0.860109</td>\n      <td>1.044509</td>\n      <td>0.468521</td>\n      <td>-0.397168</td>\n      <td>-0.213896</td>\n      <td>-0.710931</td>\n      <td>...</td>\n      <td>-0.730195</td>\n      <td>-0.736875</td>\n      <td>-0.320701</td>\n      <td>-0.320701</td>\n      <td>-0.733501</td>\n      <td>-0.733593</td>\n      <td>-0.344593</td>\n      <td>-0.344593</td>\n      <td>-1.266231</td>\n      <td>-1.291156</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.008051</td>\n      <td>0.567050</td>\n      <td>-0.575104</td>\n      <td>-0.409736</td>\n      <td>-1.751413</td>\n      <td>1.044509</td>\n      <td>-2.134375</td>\n      <td>2.517826</td>\n      <td>-0.213896</td>\n      <td>1.017777</td>\n      <td>...</td>\n      <td>0.568530</td>\n      <td>0.565571</td>\n      <td>-0.320701</td>\n      <td>-0.320701</td>\n      <td>0.567102</td>\n      <td>0.566997</td>\n      <td>-0.344593</td>\n      <td>-0.344593</td>\n      <td>0.004129</td>\n      <td>-0.020229</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.770774</td>\n      <td>-0.854388</td>\n      <td>-1.276585</td>\n      <td>-0.409736</td>\n      <td>0.922500</td>\n      <td>-0.766124</td>\n      <td>0.468521</td>\n      <td>-0.397168</td>\n      <td>-0.213896</td>\n      <td>-0.710931</td>\n      <td>...</td>\n      <td>-0.853422</td>\n      <td>-0.855341</td>\n      <td>-0.320701</td>\n      <td>-0.320701</td>\n      <td>-0.854343</td>\n      <td>-0.854434</td>\n      <td>-0.344593</td>\n      <td>-0.344593</td>\n      <td>-0.758087</td>\n      <td>-0.782785</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 201 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# or you can specify all DataBunch settings in model\n",
    "model = LightGBMClassifier(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test,\n",
    "    cat_features=None,\n",
    "    clean_and_encod_data=True,\n",
    "    cat_encoder_names=['OneHotEncoder', 'HelmertEncoder', 'HashingEncoder', 'FrequencyEncoder'],\n",
    "    num_generator_features=True, # Generator interaction Num Features\n",
    "    group_generator_features=False, # Generator Group Encoder Features\n",
    "    frequency_enc_num_features=True, \n",
    "    normalization=True,\n",
    "    clean_nan=True, # fillnan\n",
    "    verbose=1,\n",
    "    random_state=RANDOM_SEED,\n",
    "    )\n",
    "model._data.X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to make changes to the data, you can access the databunch directly in the model model._data.X_train. But I do not recommend doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T04:24:37.124919Z",
     "start_time": "2020-05-07T04:24:14.650366Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1/1 [01:12<00:00, 72.92s/it]\n",
      " Mean Score roc_auc_score on 20 Folds: 0.7449 std: 0.060826\n",
      "Test AUC:  0.832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit with default model parameters\n",
    "predicts = model.predict()\n",
    "print('Test AUC: ', round(sklearn.metrics.roc_auc_score(y_test, predicts['predict_test'][0]),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoder selection is an important part of all AutoML**    \n",
    "Even with such smart preprocessing, don't forget the basic DS rule: **Garbage in the input is garbage in the output.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[RUS] Даже с такой умной предобработкой не забывайте: Мусор на входе - мусор на выходе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}